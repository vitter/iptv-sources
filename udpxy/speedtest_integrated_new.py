#!/usr/bin/env python3
"""
IPTV(udpxy) IP æœç´¢ä¸æµ‹é€Ÿç»¼åˆå·¥å…· - æ–°ç‰ˆæœ¬

ä½¿ç”¨FOFA API æˆ–ç™»å½•Cookieè¿›è¡Œæœç´¢ï¼ŒQuake360ä½¿ç”¨Tokenè®¤è¯

åŠŸèƒ½ï¼š
1. ä» FOFA å’Œ Quake360 æœç´¢ udpxy IPï¼ˆFOFAæ”¯æŒAPIå¯†é’¥å’ŒCookieè®¤è¯ï¼ŒQuake360ä½¿ç”¨Tokenè®¤è¯ï¼‰
2. ç«¯å£è¿é€šæ€§æµ‹è¯•
3. HTTP/M3U8 æµåª’ä½“æµ‹é€Ÿ
4. ç”Ÿæˆç»“æœæ–‡ä»¶

ç”¨æ³•ï¼š
python speedtest_integrated_new.py <çœå¸‚> <è¿è¥å•†>
ä¾‹å¦‚ï¼špython speedtest_integrated_new.py Shanghai Telecom

è®¤è¯æ–¹å¼ï¼š
- FOFAï¼šé…ç½®äº†FOFA_API_KEYæ—¶ä¼˜å…ˆä½¿ç”¨APIæ–¹å¼ï¼Œå¤±è´¥æ—¶å›é€€åˆ°Cookieï¼›æœªé…ç½®åˆ™ä½¿ç”¨Cookieæ–¹å¼
- Quake360ï¼šä½¿ç”¨QUAKE360_TOKENè¿›è¡ŒAPIè®¤è¯
- FOFA å¿…é¡»é…ç½®Cookieï¼ŒQUAKE360å¿…é¡»é…ç½®Token
- æ”¯æŒå¤šçº¿ç¨‹åŠ é€Ÿæœç´¢å’Œæµ‹é€Ÿ

æ³¨æ„äº‹é¡¹ï¼š
- ç¡®ä¿åœ¨è¿è¡Œå‰è®¾ç½®äº†å¿…è¦çš„ç¯å¢ƒå˜é‡ï¼ˆè§ .env.example æ–‡ä»¶ï¼‰
- éœ€è¦å®‰è£… requests å’Œ python-dotenv åº“
"""

import argparse
import base64
import json
import math  # æ–°å¢ï¼šç”¨äºç¿»é¡µè®¡ç®—
import os
import re
import socket
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from dotenv import load_dotenv

# å¯é€‰å¯¼å…¥ BeautifulSoupï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
try:
    from bs4 import BeautifulSoup
    BEAUTIFULSOUP_AVAILABLE = True
except ImportError:
    BEAUTIFULSOUP_AVAILABLE = False
    print("Warning: BeautifulSoup not available, will use regex parsing for udpxy status")


class IPTVSpeedTest:
    """IPTV æµ‹é€Ÿä¸»ç±»"""
    
    def __init__(self, region, isp, max_pages=10, notest=False):
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        self.region = self._format_string(region)
        self.isp = self._format_string(isp)
        self.max_pages = max_pages  # æ–°å¢ï¼šæœ€å¤§ç¿»é¡µæ•°é™åˆ¶
        self.notest = notest  # æ–°å¢ï¼šæ˜¯å¦è·³è¿‡æµåª’ä½“æµ‹è¯•
        
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®å¹¶æ¸…ç†æ ¼å¼
        self.quake360_token = os.getenv('QUAKE360_TOKEN')
        self.fofa_user_agent = os.getenv('FOFA_USER_AGENT')
        self.fofa_api_key = os.getenv('FOFA_API_KEY', '')  # å¯é€‰çš„APIå¯†é’¥
        
        # æ¸…ç†Cookieå­—ç¬¦ä¸² - ç§»é™¤æ¢è¡Œç¬¦ã€å›è½¦ç¬¦å’Œå¤šä½™ç©ºæ ¼
        raw_fofa_cookie = os.getenv('FOFA_COOKIE', '')
        self.fofa_cookie = self._clean_cookie_string(raw_fofa_cookie)
        
        # Quake360 ç®€åŒ–é…ç½® - åªä½¿ç”¨Tokenè®¤è¯
        
        # éªŒè¯å¿…è¦çš„é…ç½®
        self._validate_config()
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        self._create_directories()
        
        # åŠ è½½çœä»½é…ç½®ï¼ˆä»…åœ¨éœ€è¦æµåª’ä½“æµ‹è¯•æ—¶åŠ è½½ï¼‰
        if not self.notest:
            self.city, self.stream = self._load_province_config()
        else:
            # åœ¨notestæ¨¡å¼ä¸‹ï¼Œä½¿ç”¨regionä½œä¸ºcityï¼Œstreamè®¾ä¸ºç©º
            self.city = self.region
            self.stream = ""
        
        # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
        self.output_dir = Path(f"sum/{self.isp}")
        self.temp_dir = Path("sum/tmp")
        self.ipfile_sum = self.output_dir / f"{self.city}_sum.ip"
        self.ipfile_uniq = self.output_dir / f"{self.city}_uniq.ip"
        self.speedtest_log = f"{self.isp}_speedtest_{self.city}.log"
        self.result_file = self.temp_dir / f"{self.isp}_result_fofa_{self.city}.txt"
    
    def _format_string(self, input_str):
        """æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼šé¦–å­—æ¯å¤§å†™ï¼Œå…¶ä»–å­—æ¯å°å†™"""
        return input_str.capitalize()
    
    def _clean_cookie_string(self, cookie_str):
        """æ¸…ç†Cookieå­—ç¬¦ä¸²ï¼Œç§»é™¤æ¢è¡Œç¬¦ã€å›è½¦ç¬¦å’Œå¤šä½™ç©ºæ ¼"""
        if not cookie_str:
            return ''
        
        # ç§»é™¤æ¢è¡Œç¬¦ã€å›è½¦ç¬¦ã€åˆ¶è¡¨ç¬¦
        cleaned = cookie_str.replace('\n', '').replace('\r', '').replace('\t', '')
        
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼ä½†ä¿ç•™cookieä¹‹é—´çš„å•ä¸ªç©ºæ ¼
        cleaned = ' '.join(cleaned.split())
        
        return cleaned
    
    def _validate_config(self):
        """éªŒè¯å¿…è¦çš„é…ç½®æ˜¯å¦å·²è®¾ç½®"""
        missing_configs = []
        
        # Quake360é…ç½®æ£€æŸ¥ - åªéœ€è¦Token
        if not self.quake360_token:
            missing_configs.append('QUAKE360_TOKEN')
        
        if not self.fofa_user_agent:
            missing_configs.append('FOFA_USER_AGENT')
        
        if not self.fofa_cookie:
            missing_configs.append('FOFA_COOKIE')
        
        if missing_configs:
            print("é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡é…ç½®:")
            for config in missing_configs:
                print(f"  - {config}")
            print("\nè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®è¿™äº›é…ç½®é¡¹ï¼Œæˆ–è€…åˆ›å»º.envæ–‡ä»¶ã€‚")
            print("å‚è€ƒ.env.exampleæ–‡ä»¶ä¸­çš„æ ¼å¼ã€‚")
            sys.exit(1)
        
        # æ˜¾ç¤ºé…ç½®çŠ¶æ€
        print("âœ“ é…ç½®éªŒè¯é€šè¿‡")
        print("é…ç½®çŠ¶æ€:")
        print(f"  FOFA Cookie: âœ“")
        print(f"  Quake360 Token: {'âœ“' if self.quake360_token else 'âœ—'}")
        
        # æ£€æŸ¥FOFAè®¤è¯æ–¹å¼
        if self.fofa_api_key:
            print("  â†’ FOFA å°†ä½¿ç”¨APIå¯†é’¥")
        else:
            print("  â†’ FOFA å°†ä½¿ç”¨Cookieè®¤è¯")
            
        # Quake360ä½¿ç”¨Tokenè®¤è¯
        print("  â†’ Quake360 å°†ä½¿ç”¨ Token è®¤è¯")
    
    def _create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        dirs = [
            "sum/tmp",
            f"sum/{self.isp}",
            f"template/{self.isp}"
        ]
        for dir_path in dirs:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    def _load_province_config(self):
        """åŠ è½½çœä»½é…ç½®"""
        config_file = f"{self.isp}_province_list.txt"
        if not os.path.exists(config_file):
            raise FileNotFoundError(f"é”™è¯¯: {config_file} æ–‡ä»¶ä¸å­˜åœ¨!")
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 3 and parts[0] == self.region:
                        return parts[1], parts[2]
            
            raise ValueError(f"é”™è¯¯: åœ¨ {config_file} ä¸­æœªæ‰¾åˆ°çœä»½ '{self.region}' çš„é…ç½®!")
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)
    
    def _create_session_with_retry(self):
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ä¼šè¯"""
        session = requests.Session()
        
        # è®¾ç½®é‡è¯•ç­–ç•¥
        try:
            # æ–°ç‰ˆæœ¬ä½¿ç”¨ allowed_methods
            retry_strategy = Retry(
                total=3,
                status_forcelist=[429, 500, 502, 503, 504],
                allowed_methods=["HEAD", "GET", "OPTIONS"]
            )
        except TypeError:
            # æ—§ç‰ˆæœ¬ä½¿ç”¨ method_whitelist
            retry_strategy = Retry(
                total=3,
                status_forcelist=[429, 500, 502, 503, 504],
                method_whitelist=["HEAD", "GET", "OPTIONS"]
            )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # è®¾ç½®è¯·æ±‚å¤´å’ŒCookie
        session.headers.update({
            'User-Agent': self.fofa_user_agent,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1'
        })
        
        # å•ç‹¬è®¾ç½®Cookieå¤´ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®ï¼Œå¤„ç†ç¼–ç é—®é¢˜
        if self.fofa_cookie:
            try:
                # ç¡®ä¿Cookieå­—ç¬¦ä¸²æ˜¯æ­£ç¡®ç¼–ç çš„
                if isinstance(self.fofa_cookie, bytes):
                    cookie_str = self.fofa_cookie.decode('utf-8')
                else:
                    cookie_str = str(self.fofa_cookie)
                
                # æ£€æŸ¥Cookieä¸­æ˜¯å¦åŒ…å«éASCIIå­—ç¬¦ï¼Œå¦‚æœæœ‰åˆ™è¿›è¡ŒURLç¼–ç 
                try:
                    cookie_str.encode('ascii')
                    # å¦‚æœæ²¡æœ‰å¼‚å¸¸ï¼Œè¯´æ˜æ˜¯çº¯ASCIIï¼Œç›´æ¥ä½¿ç”¨
                    session.headers['Cookie'] = cookie_str
                except UnicodeEncodeError:
                    # åŒ…å«éASCIIå­—ç¬¦ï¼Œè¿›è¡ŒURLç¼–ç å¤„ç†
                    print("æ£€æµ‹åˆ°Cookieä¸­åŒ…å«éASCIIå­—ç¬¦ï¼Œè¿›è¡Œç¼–ç å¤„ç†")
                    import urllib.parse
                    # å¯¹Cookieå€¼è¿›è¡ŒURLç¼–ç 
                    encoded_cookie = urllib.parse.quote(cookie_str, safe='=; ')
                    session.headers['Cookie'] = encoded_cookie
                    print("Cookieç¼–ç å¤„ç†å®Œæˆ")
                    
            except Exception as e:
                print(f"Cookieå¤„ç†é”™è¯¯: {e}")
                print("å°†è·³è¿‡Cookieè®¾ç½®ï¼Œä»…ä½¿ç”¨APIæ–¹å¼")
                # æ¸…ç©ºcookieï¼Œé¿å…åç»­ä½¿ç”¨
                self.fofa_cookie = None
        
        return session
    
    def search_fofa_api(self, query):
        """ä½¿ç”¨FOFA APIæœç´¢IP - æ”¯æŒç¿»é¡µè·å–å¤šé¡µæ•°æ®"""
        print("===============ä» FOFA API æ£€ç´¢ IP+ç«¯å£===============")
        
        # ä½¿ç”¨base64ç¼–ç æŸ¥è¯¢
        query_b64 = base64.b64encode(query.encode()).decode().replace('\n', '')
        
        print(f"æœç´¢æŸ¥è¯¢: {query}")
        print(f"æœ€å¤§ç¿»é¡µæ•°é™åˆ¶: {self.max_pages} é¡µ")
        
        # æ„å»ºAPIè¯·æ±‚URL
        api_url = "https://fofa.info/api/v1/search/all"
        all_ip_ports = []
        
        try:
            # åˆ›å»ºsession
            session = requests.Session()
            session.headers.update({
                'User-Agent': self.fofa_user_agent,
                'Accept': 'application/json'
            })
            
            # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼Œè·å–æ€»æ•°æ®é‡
            params = {
                'key': self.fofa_api_key,
                'qbase64': query_b64,
                'fields': 'ip,port,host',  # æŒ‡å®šè¿”å›å­—æ®µ
                'size': 10,  # æ¯é¡µæ•°é‡
                'page': 1,    # é¡µç 
                'full': 'false'  # æœç´¢ä¸€å¹´å†…æ•°æ®
            }
            
            print(f"FOFA API URL: {api_url}")
            print(f"æŸ¥è¯¢å‚æ•°: key={self.fofa_api_key[:10]}..., size={params['size']}")
            
            print("å‘é€ç¬¬ä¸€æ¬¡è¯·æ±‚è·å–æ€»æ•°æ®é‡...")
            time.sleep(1)  # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
            
            response = session.get(api_url, params=params, timeout=30)
            response.raise_for_status()
            
            # æ˜ç¡®è®¾ç½®å“åº”ç¼–ç ä¸ºUTF-8
            response.encoding = 'utf-8'
            
            print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            
            # è§£æJSONå“åº”
            response_json = response.json()
            
            # æ£€æŸ¥APIå“åº”é”™è¯¯
            if response_json.get('error', False):
                error_msg = response_json.get('errmsg', 'æœªçŸ¥é”™è¯¯')
                print(f"FOFA APIé”™è¯¯: {error_msg}")
                return []
            
            # è·å–ç»“æœæ•°æ®
            total_size = response_json.get('size', 0)
            current_page = response_json.get('page', 1)
            results = response_json.get('results', [])
            
            print(f"APIè¿”å›æ€»æ•°æ®é‡: {total_size}")
            print(f"å½“å‰é¡µ: {current_page}, å½“å‰é¡µç»“æœæ•°: {len(results)}")
            
            # è®¡ç®—æ€»é¡µæ•°
            page_size = 10
            total_pages = (total_size + page_size - 1) // page_size  # å‘ä¸Šå–æ•´
            
            # åº”ç”¨æœ€å¤§é¡µæ•°é™åˆ¶
            actual_pages = min(total_pages, self.max_pages)
            print(f"æ€»é¡µæ•°: {total_pages}, å®é™…è·å–é¡µæ•°: {actual_pages}")
            
            # å¤„ç†ç¬¬ä¸€é¡µæ•°æ®
            page_ip_ports = self._extract_fofa_api_results(results)
            all_ip_ports.extend(page_ip_ports)
            print(f"ç¬¬1é¡µæå–åˆ° {len(page_ip_ports)} ä¸ªIP:PORT")
            
            # å¦‚æœæœ‰å¤šé¡µï¼Œç»§ç»­è·å–å…¶ä»–é¡µçš„æ•°æ®
            if actual_pages > 1:
                for page in range(2, actual_pages + 1):
                    print(f"æ­£åœ¨è·å–ç¬¬ {page}/{actual_pages} é¡µæ•°æ®...")
                    
                    # æ›´æ–°é¡µç å‚æ•°
                    params['page'] = page
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
                    time.sleep(1)
                    
                    try:
                        response = session.get(api_url, params=params, timeout=30)
                        response.raise_for_status()
                        
                        # æ˜ç¡®è®¾ç½®å“åº”ç¼–ç ä¸ºUTF-8
                        response.encoding = 'utf-8'
                        
                        response_json = response.json()
                        
                        if response_json.get('error', False):
                            error_msg = response_json.get('errmsg', 'æœªçŸ¥é”™è¯¯')
                            print(f"ç¬¬{page}é¡µFOFA APIé”™è¯¯: {error_msg}")
                            continue
                        
                        results = response_json.get('results', [])
                        page_ip_ports = self._extract_fofa_api_results(results)
                        all_ip_ports.extend(page_ip_ports)
                        print(f"ç¬¬{page}é¡µæå–åˆ° {len(page_ip_ports)} ä¸ªIP:PORT")
                        
                    except KeyboardInterrupt:
                        print(f"\nç”¨æˆ·ä¸­æ–­ï¼Œå·²è·å–å‰ {page-1} é¡µæ•°æ®")
                        break
                    except Exception as e:
                        print(f"è·å–ç¬¬{page}é¡µæ•°æ®å¤±è´¥: {e}")
                        continue
            
            # å»é‡
            unique_ips = list(set(all_ip_ports))
            
            print(f"FOFA APIæ€»å…±æå–åˆ° {len(all_ip_ports)} ä¸ªIP:PORT")
            print(f"å»é‡åå…± {len(unique_ips)} ä¸ªå”¯ä¸€IP")
            
            if unique_ips:
                print("å‰10ä¸ªIP:")
                for ip in unique_ips[:10]:
                    print(f"  {ip}")
                if len(unique_ips) > 10:
                    print(f"... è¿˜æœ‰ {len(unique_ips) - 10} ä¸ª")
                return unique_ips
            else:
                print("FOFA APIæœç´¢æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆIP")
                return []
                
        except KeyboardInterrupt:
            print(f"\nç”¨æˆ·ä¸­æ–­ï¼Œå·²è·å– {len(all_ip_ports)} ä¸ªç»“æœ")
            return list(set(all_ip_ports))  # è¿”å›å·²è·å–çš„å»é‡ç»“æœ
        except requests.exceptions.RequestException as e:
            print(f"FOFA APIè¯·æ±‚å¤±è´¥: {e}")
            return []
        except Exception as e:
            print(f"FOFA APIæœç´¢å¼‚å¸¸: {e}")
            return []
    
    def _extract_fofa_api_results(self, results):
        """æå–FOFA APIæœç´¢ç»“æœæ•°æ®"""
        ip_ports = []
        
        for result in results:
            if len(result) >= 2:  # ç¡®ä¿æœ‰IPå’Œç«¯å£æ•°æ®
                # FOFA APIè¿”å›æ ¼å¼é€šå¸¸æ˜¯ï¼š[ip, port, host] çš„é¡ºåº
                ip = result[0] if len(result) > 0 else None
                port = result[1] if len(result) > 1 else None
                
                # å¤„ç†IPå’Œç«¯å£
                if ip and port:
                    # æ¸…ç†IPåœ°å€ï¼ˆç§»é™¤åè®®å‰ç¼€ï¼‰
                    ip = str(ip)
                    if ip.startswith('http://'):
                        ip = ip[7:]
                    elif ip.startswith('https://'):
                        ip = ip[8:]
                    
                    # å¦‚æœIPåŒ…å«ç«¯å£ï¼Œæå–IPéƒ¨åˆ†
                    if ':' in ip:
                        ip = ip.split(':')[0]
                    
                    # éªŒè¯IPæ ¼å¼
                    if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', ip):
                        ip_port = f"{ip}:{port}"
                        ip_ports.append(ip_port)
        
        return ip_ports
    
    def search_fofa_cookie(self, query):
        """ä½¿ç”¨FOFA Cookieæœç´¢IP - æ”¯æŒç¿»é¡µè·å–å¤šé¡µæ•°æ®"""
        print("===============ä» FOFA æ£€ç´¢ IP+ç«¯å£ (ä½¿ç”¨Cookieè®¤è¯)===============")
        
        query_b64 = base64.b64encode(query.encode()).decode().replace('\n', '')
        
        print(f"æœç´¢æŸ¥è¯¢: {query}")
        print(f"æœ€å¤§ç¿»é¡µæ•°é™åˆ¶: {self.max_pages} é¡µ")
        
        all_ip_ports = []
        
        try:
            session = self._create_session_with_retry()
            
            # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼Œè·å–æ€»æ•°æ®é‡å’Œé¡µé¢ä¿¡æ¯
            first_url = f"https://fofa.info/result?qbase64={query_b64}&page=1&page_size=10"
            print(f"FOFA URL: {first_url}")
            
            print("å‘é€ç¬¬ä¸€æ¬¡è¯·æ±‚è·å–æ€»æ•°æ®é‡...")
            response = session.get(first_url, timeout=30)
            response.raise_for_status()
            
            # æ˜ç¡®è®¾ç½®å“åº”ç¼–ç ä¸ºUTF-8
            response.encoding = 'utf-8'
            
            print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"å“åº”å†…å®¹é•¿åº¦: {len(response.text)} å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦è¢«æ‹’ç»è®¿é—®
            if '[-3000]' in response.text:
                print("è¢«æ‹’ç»è®¿é—® [-3000] - å¯èƒ½éœ€è¦æ›´æ–°Cookie")
                return []
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
            if 'login' in response.url.lower() or 'ç™»å½•' in response.text:
                print("æ£€æµ‹åˆ°éœ€è¦ç™»å½• - è¯·æ£€æŸ¥Cookieæ˜¯å¦æœ‰æ•ˆ")
                return []
            
            # æå–é¡µé¢ä¿¡æ¯
            total_count, page_size = self._extract_fofa_page_info(response.text)
            print(f"æ€»æ•°æ®é‡: {total_count}")
            print(f"é¡µé¢å¤§å°: {page_size}")
            
            # è®¡ç®—æ€»é¡µæ•°
            total_pages = (total_count + page_size - 1) // page_size if total_count > 0 else 1  # å‘ä¸Šå–æ•´
            
            # åº”ç”¨æœ€å¤§é¡µæ•°é™åˆ¶
            actual_pages = min(total_pages, self.max_pages)
            print(f"æ€»é¡µæ•°: {total_pages}, å®é™…è·å–é¡µæ•°: {actual_pages}")
            
            # å¤„ç†ç¬¬ä¸€é¡µæ•°æ®
            first_page_ips = self._extract_fofa_cookie_results(response.text)
            all_ip_ports.extend(first_page_ips)
            print(f"ç¬¬1é¡µæå–åˆ° {len(first_page_ips)} ä¸ªIP")
            
            # å¦‚æœæœ‰å¤šé¡µï¼Œç»§ç»­è·å–å…¶ä»–é¡µçš„æ•°æ®
            if actual_pages > 1:
                for page in range(2, actual_pages + 1):
                    print(f"æ­£åœ¨è·å–ç¬¬ {page}/{actual_pages} é¡µæ•°æ®...")
                    
                    page_url = f"https://fofa.info/result?qbase64={query_b64}&page={page}&page_size={page_size}"
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…è¢«é™æµ
                    time.sleep(2)
                    
                    try:
                        response = session.get(page_url, timeout=30)
                        response.raise_for_status()
                        
                        # æ˜ç¡®è®¾ç½®å“åº”ç¼–ç ä¸ºUTF-8
                        response.encoding = 'utf-8'
                        
                        # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
                        if '[-3000]' in response.text:
                            print(f"ç¬¬{page}é¡µè¢«æ‹’ç»è®¿é—® [-3000]")
                            continue
                        
                        if 'login' in response.url.lower() or 'ç™»å½•' in response.text:
                            print(f"ç¬¬{page}é¡µéœ€è¦é‡æ–°ç™»å½•")
                            break
                        
                        page_ips = self._extract_fofa_cookie_results(response.text)
                        all_ip_ports.extend(page_ips)
                        print(f"ç¬¬{page}é¡µæå–åˆ° {len(page_ips)} ä¸ªIP")
                        
                    except KeyboardInterrupt:
                        print(f"\nç”¨æˆ·ä¸­æ–­ï¼Œå·²è·å–å‰ {page-1} é¡µæ•°æ®")
                        break
                    except Exception as e:
                        print(f"è·å–ç¬¬{page}é¡µæ•°æ®å¤±è´¥: {e}")
                        continue
            
            # å»é‡ç»“æœ
            unique_ips = list(set(all_ip_ports))
            
            print(f"FOFA Cookieæ€»å…±æå–åˆ° {len(all_ip_ports)} ä¸ªIP:PORT")
            print(f"å»é‡åå…± {len(unique_ips)} ä¸ªå”¯ä¸€IP")
            
            if unique_ips:
                print("å‰10ä¸ªIP:")
                for ip in unique_ips[:10]:
                    print(f"  {ip}")
                if len(unique_ips) > 10:
                    print(f"... è¿˜æœ‰ {len(unique_ips) - 10} ä¸ª")
                return unique_ips
            else:
                print("FOFAæœç´¢æœªæ‰¾åˆ°ä»»ä½•IP")
                return []
                
        except KeyboardInterrupt:
            print(f"\nç”¨æˆ·ä¸­æ–­ï¼Œå·²è·å– {len(all_ip_ports)} ä¸ªç»“æœ")
            return list(set(all_ip_ports))  # è¿”å›å·²è·å–çš„å»é‡ç»“æœ
        except requests.exceptions.RequestException as e:
            print(f"FOFAè¯·æ±‚å¤±è´¥: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"å“åº”çŠ¶æ€ç : {e.response.status_code}")
                print(f"å“åº”å¤´: {dict(e.response.headers)}")
            return []
        except UnicodeEncodeError as e:
            print(f"FOFAæœç´¢ç¼–ç é”™è¯¯: {e}")
            print(f"é”™è¯¯å‘ç”Ÿåœ¨: ç¼–ç  '{e.object[e.start:e.end]}' ä½¿ç”¨ '{e.encoding}' ç¼–ç ")
            print("è¿™é€šå¸¸æ˜¯ç”±äºCookieä¸­åŒ…å«äº†éASCIIå­—ç¬¦å¯¼è‡´çš„")
            print("å»ºè®®æ£€æŸ¥FOFA_COOKIEç¯å¢ƒå˜é‡ä¸­æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦")
            return []
        except Exception as e:
            print(f"FOFAæœç´¢å¼‚å¸¸: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            print("é”™è¯¯å †æ ˆ:")
            traceback.print_exc()
            return []
    
    def _extract_fofa_page_info(self, content):
        """æå–FOFAé¡µé¢çš„æ€»æ•°é‡å’Œé¡µé¢å¤§å°ä¿¡æ¯"""
        total_count = 0
        page_size = 10
        
        try:
            # æ–¹æ³•1: å°è¯•ä»JavaScriptå˜é‡ä¸­æå–æ€»æ•°
            # æ”¯æŒå¤šç§å¯èƒ½çš„å˜é‡åï¼ˆbI, aC, ç­‰æ··æ·†åçš„å˜é‡åï¼‰
            total_patterns = [
                r'bI\.total\s*=\s*(\d+)',     # åŸå§‹æ¨¡å¼
                r'aC\.total\s*=\s*(\d+)',     # æ–°å‘ç°çš„æ¨¡å¼
                r'[a-zA-Z]{1,3}\.total\s*=\s*(\d+)',  # é€šç”¨æ¨¡å¼ï¼ŒåŒ¹é…ä»»æ„1-3ä¸ªå­—æ¯çš„å˜é‡å
            ]
            
            for pattern in total_patterns:
                total_match = re.search(pattern, content)
                if total_match:
                    total_count = int(total_match.group(1))
                    print(f"ä»å˜é‡æå–åˆ°æ€»æ•°: {total_count} (æ¨¡å¼: {pattern})")
                    break
            
            # æ–¹æ³•1.5: ä¸“é—¨å¤„ç†è¿ç»­èµ‹å€¼çš„æƒ…å†µï¼Œå¦‚ aC.size=10;aC.total=503
            if total_count == 0:
                # æŸ¥æ‰¾è¿ç»­èµ‹å€¼æ¨¡å¼
                continuous_pattern = r'([a-zA-Z]{1,4})\.(?:size|total)\s*=\s*\d+[;\s]*\1\.(?:size|total)\s*=\s*\d+'
                continuous_match = re.search(continuous_pattern, content)
                if continuous_match:
                    var_name = continuous_match.group(1)
                    # æå–è¿™ä¸ªå˜é‡çš„totalå€¼
                    total_pattern = f'{var_name}\\.total\\s*=\\s*(\\d+)'
                    total_match = re.search(total_pattern, content)
                    if total_match:
                        total_count = int(total_match.group(1))
                        print(f"ä»è¿ç»­èµ‹å€¼æå–åˆ°æ€»æ•°: {total_count} (å˜é‡: {var_name})")
            
            # æ–¹æ³•2: å°è¯•ä»é¡µé¢HTMLä¸­æŸ¥æ‰¾æ•°æ®æ€»æ•°ä¿¡æ¯
            if total_count == 0:
                # æŸ¥æ‰¾ç±»ä¼¼ "å…±xxxæ¡æ•°æ®" çš„æ¨¡å¼
                count_patterns = [
                    r'å…±\s*(\d+)\s*æ¡',
                    r'total:\s*(\d+)',
                    r'count:\s*(\d+)',
                    r'results:\s*(\d+)'
                ]
                
                for pattern in count_patterns:
                    match = re.search(pattern, content, re.IGNORECASE)
                    if match:
                        total_count = int(match.group(1))
                        print(f"ä»é¡µé¢å†…å®¹æå–åˆ°æ€»æ•°: {total_count}")
                        break
            
            # æ–¹æ³•3: å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œæ ¹æ®å®é™…æå–çš„IPæ•°é‡ä¼°ç®—
            if total_count == 0:
                # è®¡ç®—é¡µé¢ä¸­å®é™…çš„IPæ•°é‡æ¥ä¼°ç®—
                ip_pattern = r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+\b'
                found_ips = re.findall(ip_pattern, content)
                if found_ips:
                    actual_count = len(set(found_ips))  # å»é‡åçš„æ•°é‡
                    print(f"æ ¹æ®é¡µé¢å®é™…IPæ•°é‡ä¼°ç®—: å½“å‰é¡µæœ‰ {actual_count} ä¸ªIP")
                    # å¦‚æœç¬¬ä¸€é¡µå°±æœ‰è¾ƒå¤šIPï¼Œå¯èƒ½æ€»æ•°æ›´å¤š
                    if actual_count >= 10:
                        total_count = actual_count * 3  # ä¿å®ˆä¼°è®¡
                        print(f"ä¼°ç®—æ€»æ•°æ®é‡: {total_count}")
            
            # è°ƒè¯•ï¼šå¦‚æœä»ç„¶æ— æ³•æå–æ•°æ®ï¼Œå°è¯•æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„JavaScriptå˜é‡èµ‹å€¼
            if total_count == 0:
                print("  [è°ƒè¯•] æ­£åœ¨æŸ¥æ‰¾é¡µé¢ä¸­çš„JavaScriptå˜é‡...")
                # æŸ¥æ‰¾æ‰€æœ‰ç±»ä¼¼ xx.total = æ•°å­— æˆ– xx.size = æ•°å­— çš„æ¨¡å¼
                debug_patterns = [
                    r'([a-zA-Z]{1,4})\.total\s*=\s*(\d+)',
                    r'([a-zA-Z]{1,4})\.size\s*=\s*(\d+)',
                    r'total["\']?\s*:\s*(\d+)',
                    r'size["\']?\s*:\s*(\d+)',
                ]
                
                for pattern in debug_patterns:
                    matches = re.findall(pattern, content, re.IGNORECASE)
                    if matches:
                        for match in matches[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªåŒ¹é…
                            if len(match) == 2:  # å˜é‡åå’Œå€¼
                                print(f"    å‘ç°å˜é‡: {match[0]}.total/size = {match[1]}")
                            else:  # åªæœ‰å€¼
                                print(f"    å‘ç°å€¼: {match}")
            
            # æŸ¥æ‰¾é¡µé¢å¤§å°çš„å¤šç§æ¨¡å¼
            size_patterns = [
                r'bI\.size\s*=\s*(\d+)',      # åŸå§‹æ¨¡å¼
                r'aC\.size\s*=\s*(\d+)',      # æ–°å‘ç°çš„æ¨¡å¼
                r'[a-zA-Z]{1,3}\.size\s*=\s*(\d+)',   # é€šç”¨æ¨¡å¼
            ]
            
            for pattern in size_patterns:
                size_match = re.search(pattern, content)
                if size_match:
                    extracted_page_size = int(size_match.group(1))
                    print(f"ä»å˜é‡æå–åˆ°é¡µé¢å¤§å°: {extracted_page_size} (æ¨¡å¼: {pattern})")
                    if extracted_page_size != page_size:
                        print(f"è­¦å‘Š: æå–çš„é¡µé¢å¤§å°({extracted_page_size})ä¸é¢„æœŸ({page_size})ä¸ç¬¦")
                        if extracted_page_size > 0:
                            page_size = extracted_page_size
                    break
            
            # å¦‚æœä»æœªæ‰¾åˆ°é¡µé¢å¤§å°ï¼Œå°è¯•ä»æ€»æ•°æå–ä¸­ä½¿ç”¨çš„åŒä¸€å˜é‡å
            if page_size == 10 and total_count > 0:  # å¦‚æœæ€»æ•°å·²æ‰¾åˆ°ä½†é¡µé¢å¤§å°è¿˜æ˜¯é»˜è®¤å€¼
                # ä»å‰é¢æˆåŠŸçš„totalæå–ä¸­è·å–å˜é‡å
                for pattern in total_patterns:
                    total_match = re.search(pattern, content)
                    if total_match:
                        # æå–å˜é‡åéƒ¨åˆ†
                        var_match = re.match(r'([a-zA-Z]{1,3})\.', pattern)
                        if var_match:
                            var_name = var_match.group(1)
                            size_pattern = f'{var_name}\\.size\\s*=\\s*(\\d+)'
                            size_match = re.search(size_pattern, content)
                            if size_match:
                                extracted_page_size = int(size_match.group(1))
                                print(f"ä»åŒå˜é‡æå–åˆ°é¡µé¢å¤§å°: {extracted_page_size} (å˜é‡: {var_name})")
                                if extracted_page_size > 0:
                                    page_size = extracted_page_size
                                break
                        break
                        
        except Exception as e:
            print(f"æå–é¡µé¢ä¿¡æ¯å¤±è´¥: {e}")
        
        return total_count, page_size
    
    def _extract_fofa_cookie_results(self, content):
        """æå–FOFA Cookieæœç´¢ç»“æœä¸­çš„IP:PORTæ•°æ®"""
        all_ips = []
        
        # æ–¹æ³•1ï¼šä½¿ç”¨ç¬¬ä¸€ç§æ–¹å¼ - åŒ¹é…è¡Œé¦–çš„IP:PORTæ ¼å¼
        line_pattern = r'^\s*(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+)\s*$'
        lines = content.split('\n')
        method1_ips = []
        
        for line in lines:
            match = re.match(line_pattern, line)
            if match:
                method1_ips.append(match.group(1))
        
        # æ–¹æ³•2ï¼šä½¿ç”¨ç¬¬äºŒç§æ–¹å¼ - å…¨æ–‡åŒ¹é…IP:PORT
        ip_pattern = r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+\b'
        method2_ips = re.findall(ip_pattern, content)
        
        # åˆå¹¶ä¸¤ç§æ–¹æ³•çš„ç»“æœ
        all_ips = method1_ips + method2_ips
        
        return all_ips
    
    def search_fofa_ips(self):
        """ä» FOFA æœç´¢ IP - ä¼˜å…ˆä½¿ç”¨APIï¼Œå›é€€åˆ°Cookie"""
        # æ ¹æ®è¿è¥å•†ç±»å‹æ„å»ºæœç´¢æŸ¥è¯¢ï¼ˆç®€åŒ–ä¸ºå•ä¸ªæŸ¥è¯¢ï¼‰
        if self.isp.lower() == 'mobile':
            query = f'"udpxy" && country="CN" && region="{self.region}" && (org="{self.region} Mobile Communication Company Limited" || org="{self.region} Mobile Communications Co." || org="China Mobile Communicaitons Corporation" || org="China Mobile communications corporation" || org="China Mobile Communications Group Co., Ltd." || org="{self.region} Mobile Communications Co.,Ltd." || org="{self.region} Mobile Communications Co.,Ltd" || org="China Mobile Group {self.region} communications corporation" || org="China Mobile Group {self.region} Co.") && protocol="http"'
        elif self.isp.lower() == 'telecom':
            query = f'"udpxy" && country="CN" && region="{self.region}" && (org="Chinanet" || org="China Telecom" || org="CHINA TELECOM" || org="China Telecom Group" || org="{self.region} Telecom" || org="CHINANET {self.region} province network" || org="CHINANET {self.region} province backbone") && protocol="http"'
        elif self.isp.lower() == 'unicom':
            query = f'"udpxy" && country="CN" && region="{self.region}" && (org="CHINA UNICOM China169 Backbone" || org="China Unicom" || org="China Unicom IP network" || org="CHINA UNICOM Industrial Internet Backbone" || org="China Unicom {self.region} network" || org="China Unicom {self.region} IP network" || org="China Unicom {self.region} Province Network" || org="UNICOM {self.region} province network" || org="China Unicom IP network China169 {self.region} province") && protocol="http"'
        else:
            # é»˜è®¤æŸ¥è¯¢
            query = f'"udpxy" && country="CN" && region="{self.region}" && protocol="http"'
        
        print(f"ä½¿ç”¨FOFAæŸ¥è¯¢")
        
        # ä¼˜å…ˆä½¿ç”¨APIæ–¹å¼ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°Cookieæ–¹å¼
        if self.fofa_api_key:
            print("ä½¿ç”¨APIæ–¹å¼è¿›è¡ŒæŸ¥è¯¢")
            api_results = self.search_fofa_api(query)
            if api_results:
                print(f"FOFA APIæ‰¾åˆ° {len(api_results)} ä¸ªIP")
                return api_results
            else:
                print("APIæ–¹å¼å¤±è´¥ï¼Œå°è¯•Cookieæ–¹å¼")
                cookie_results = self.search_fofa_cookie(query)
                if cookie_results:
                    print(f"FOFA Cookieæ‰¾åˆ° {len(cookie_results)} ä¸ªIP")
                    return cookie_results
        else:
            print("ä½¿ç”¨Cookieæ–¹å¼è¿›è¡ŒæŸ¥è¯¢")
            cookie_results = self.search_fofa_cookie(query)
            if cookie_results:
                print(f"FOFA Cookieæ‰¾åˆ° {len(cookie_results)} ä¸ªIP")
                return cookie_results
        
        print("FOFAæœç´¢æœªæ‰¾åˆ°ä»»ä½•IP")
        return []
    
    def search_quake360_ips(self):
        """ä» Quake360 æœç´¢ IP - ä½¿ç”¨Tokenè®¤è¯"""
        print(f"===============ä» Quake360 æ£€ç´¢ IP ({self.region})=================")
        
        if not self.quake360_token:
            print("âŒ æœªé…ç½®QUAKE360_TOKENï¼Œè·³è¿‡Quake360æœç´¢")
            return []
        
        print("ğŸ”‘ ä½¿ç”¨ Quake360 Token æ–¹å¼æœç´¢")
        return self.search_quake360_api()
    
    def search_quake360_api(self):
        """ä» Quake360 æœç´¢ IP - APIæ–¹å¼ï¼Œæ”¯æŒç¿»é¡µè·å–å¤šé¡µæ•°æ®"""
        print("--- Quake360 API æœç´¢ ---")
        
        # æ ¹æ®è¿è¥å•†ç±»å‹æ„å»ºæœç´¢æŸ¥è¯¢
        if self.isp.lower() == 'telecom':
            query = f'"udpxy" AND country: "China" AND province: "{self.region}" AND isp: "ä¸­å›½ç”µä¿¡" AND protocol: "http"'
        elif self.isp.lower() == 'unicom':
            query = f'"udpxy" AND country: "China" AND province: "{self.region}" AND isp: "ä¸­å›½è”é€š" AND protocol: "http"'
        elif self.isp.lower() == 'mobile':
            query = f'"udpxy" AND country: "China" AND province: "{self.region}" AND isp: "ä¸­å›½ç§»åŠ¨" AND protocol: "http"'
        else:
            # é»˜è®¤æŸ¥è¯¢
            query = f'"udpxy" AND country: "China" AND province: "{self.region}" AND protocol: "http"'
        
        print(f"æŸ¥è¯¢å‚æ•°: {query}")
        print(f"æœ€å¤§ç¿»é¡µæ•°é™åˆ¶: {self.max_pages} é¡µ")
        
        all_ip_ports = []
        
        # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼Œè·å–æ€»æ•°æ®é‡
        query_data = {
            "query": query,
            "start": 0,
            "size": 10,  # æ¯é¡µ100æ¡æ•°æ®
            "ignore_cache": False,
            "latest": True,
            "shortcuts": "635fcb52cc57190bd8826d09"
        }
        
        headers = {
            'X-QuakeToken': self.quake360_token,
            'Content-Type': 'application/json',
            'User-Agent': self.fofa_user_agent
        }
        
        try:
            print("å‘é€ç¬¬ä¸€æ¬¡è¯·æ±‚è·å–æ€»æ•°æ®é‡...")
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
            time.sleep(2)
            
            response = requests.post(
                'https://quake.360.net/api/v3/search/quake_service',
                headers=headers,
                json=query_data,
                timeout=30
            )
            response.raise_for_status()
            
            print(f"APIå“åº”çŠ¶æ€ç : {response.status_code}")
            
            # è§£æJSONå“åº”
            response_json = response.json()
            
            # æ£€æŸ¥APIé”™è¯¯
            code = response_json.get('code')
            if code and str(code) not in ['0', '200', 'success']:
                error_message = response_json.get('message', 'æœªçŸ¥é”™è¯¯')
                print(f"Quake360 APIé”™è¯¯: {code} - {error_message}")
                if str(code) == 'q5000':
                    print("  è¿™æ˜¯Quake360æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œå¯èƒ½æ˜¯ä¸´æ—¶é—®é¢˜ï¼Œå»ºè®®ç¨åé‡è¯•")
                return []
            
            # è·å–æ€»æ•°æ®é‡å’Œåˆ†é¡µä¿¡æ¯
            meta = response_json.get('meta', {})
            pagination = meta.get('pagination', {})
            total_count = pagination.get('total', 0)
            page_size = pagination.get('page_size', 10)
            current_page = pagination.get('page_index', 1)
            
            print(f"æ€»æ•°æ®é‡: {total_count}")
            print(f"å½“å‰é¡µ: {current_page}, é¡µé¢å¤§å°: {page_size}")
            
            # è®¡ç®—æ€»é¡µæ•°
            total_pages = (total_count + page_size - 1) // page_size if total_count > 0 else 1  # å‘ä¸Šå–æ•´
            
            # åº”ç”¨æœ€å¤§é¡µæ•°é™åˆ¶
            actual_pages = min(total_pages, self.max_pages)
            print(f"æ€»é¡µæ•°: {total_pages}, å®é™…è·å–é¡µæ•°: {actual_pages}")
            
            # å¤„ç†ç¬¬ä¸€é¡µæ•°æ®
            first_page_data = response_json.get('data', [])
            page_ip_ports = self._extract_quake360_results(first_page_data)
            all_ip_ports.extend(page_ip_ports)
            print(f"ç¬¬1é¡µæå–åˆ° {len(page_ip_ports)} ä¸ªIP:PORT")
            
            # å¦‚æœæœ‰å¤šé¡µï¼Œç»§ç»­è·å–å…¶ä»–é¡µçš„æ•°æ®
            if actual_pages > 1 and total_count > 0:
                for page in range(2, actual_pages + 1):
                    print(f"æ­£åœ¨è·å–ç¬¬ {page}/{actual_pages} é¡µæ•°æ®...")
                    
                    # æ›´æ–°åˆ†é¡µå‚æ•°
                    query_data['start'] = (page - 1) * page_size
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
                    time.sleep(2)
                    
                    try:
                        response = requests.post(
                            'https://quake.360.net/api/v3/search/quake_service',
                            headers=headers,
                            json=query_data,
                            timeout=30
                        )
                        response.raise_for_status()
                        
                        response_json = response.json()
                        
                        # æ£€æŸ¥é”™è¯¯
                        code = response_json.get('code')
                        if code and str(code) not in ['0', '200', 'success']:
                            error_message = response_json.get('message', 'æœªçŸ¥é”™è¯¯')
                            if str(code) == 'q5000':
                                print(f"ç¬¬{page}é¡µQuake360æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè·³è¿‡è¯¥é¡µ")
                            else:
                                print(f"ç¬¬{page}é¡µQuake360 APIé”™è¯¯: {code} - {error_message}")
                            continue
                        
                        page_data = response_json.get('data', [])
                        page_ip_ports = self._extract_quake360_results(page_data)
                        all_ip_ports.extend(page_ip_ports)
                        print(f"ç¬¬{page}é¡µæå–åˆ° {len(page_ip_ports)} ä¸ªIP:PORT")
                        
                    except KeyboardInterrupt:
                        print(f"\nç”¨æˆ·ä¸­æ–­ï¼Œå·²è·å–å‰ {page-1} é¡µæ•°æ®")
                        break
                    except Exception as e:
                        print(f"è·å–ç¬¬{page}é¡µæ•°æ®å¤±è´¥: {e}")
                        continue
            
            # å»é‡ç»“æœ
            unique_ips = list(set(all_ip_ports))
            
            print(f"Quake360 APIæ€»å…±æå–åˆ° {len(all_ip_ports)} ä¸ªIP:PORT")
            print(f"å»é‡åå…± {len(unique_ips)} ä¸ªå”¯ä¸€IP")
            
            if unique_ips:
                # æ˜¾ç¤ºå‰10ä¸ªIP
                print("æå–åˆ°çš„IPåœ°å€:")
                for ip in unique_ips[:10]:
                    print(f"  {ip}")
                if len(unique_ips) > 10:
                    print(f"  ... è¿˜æœ‰ {len(unique_ips) - 10} ä¸ª")
                
                return unique_ips
            else:
                print("Quake360 APIæœªæ‰¾åˆ°æœ‰æ•ˆçš„IPåœ°å€")
                return []
                
        except KeyboardInterrupt:
            print(f"\nç”¨æˆ·ä¸­æ–­ï¼Œå·²è·å– {len(all_ip_ports)} ä¸ªç»“æœ")
            return list(set(all_ip_ports))  # è¿”å›å·²è·å–çš„å»é‡ç»“æœ
        except requests.exceptions.RequestException as e:
            print(f"Quake360 APIè¯·æ±‚å¤±è´¥: {e}")
            return []
        except Exception as e:
            print(f"Quake360 APIæœç´¢å¼‚å¸¸: {e}")
            return []
    
    def _extract_quake360_results(self, data_list):
        """æå–Quake360æœç´¢ç»“æœæ•°æ®"""
        ip_ports = []
        
        for item in data_list:
            if isinstance(item, dict):
                # æå–IPåœ°å€ - å°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µå
                ip = (item.get('ip') or 
                      item.get('host') or 
                      item.get('address') or
                      item.get('target') or
                      item.get('service', {}).get('ip') if isinstance(item.get('service'), dict) else None)
                
                # æå–ç«¯å£ - å°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µå
                port = (item.get('port') or 
                       item.get('service_port') or 
                       item.get('target_port') or
                       item.get('service', {}).get('port') if isinstance(item.get('service'), dict) else None)
                
                # ç»„åˆIP:PORT
                if ip and port:
                    # ç¡®ä¿IPæ˜¯æœ‰æ•ˆçš„IPåœ°å€æ ¼å¼ï¼ˆä¸åŒ…å«åŸŸåï¼‰
                    if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', str(ip)):
                        ip_port = f"{ip}:{port}"
                        ip_ports.append(ip_port)
        
        return ip_ports
    
        
    def test_port_connectivity(self, ip_port, timeout=2):
        """æµ‹è¯•ç«¯å£è¿é€šæ€§"""
        try:
            ip, port = ip_port.split(':')
            port = int(port)
            
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(timeout)
            result = sock.connect_ex((ip, port))
            sock.close()
            
            return result == 0
        except Exception:
            return False
    
    def test_udpxy_service(self, ip_port, timeout=5):
        """æµ‹è¯•æ˜¯å¦ä¸ºudpxyæœåŠ¡å™¨"""
        try:
            ip, port = ip_port.split(':')
            port = int(port)
            
            # åˆ›å»ºsocketè¿æ¥
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(timeout)
            
            try:
                sock.connect((ip, port))
                
                # å‘é€HTTP GETè¯·æ±‚
                request = f"GET / HTTP/1.1\r\nHost: {ip}:{port}\r\nConnection: close\r\nUser-Agent: udpxy-test\r\n\r\n"
                sock.send(request.encode())
                
                # æ¥æ”¶å“åº”
                response = b""
                start_time = time.time()
                
                while True:
                    try:
                        sock.settimeout(2)
                        chunk = sock.recv(1024)
                        if not chunk:
                            break
                        response += chunk
                        
                        if len(response) > 512 or (time.time() - start_time) > 3:
                            break
                            
                    except socket.timeout:
                        break
                
                sock.close()
                
                # è§£ç å“åº”å¹¶æ£€æŸ¥æ˜¯å¦åŒ…å«udpxyæ ‡è¯†
                text = response.decode(errors="ignore")
                text_lower = text.lower()
                
                # udpxyåˆ¤æ–­æ ‡å‡†
                udpxy_indicators = [
                    'server:' in text_lower and 'udpxy' in text_lower,
                    'udpxy' in text_lower and 'unrecognized request' in text_lower,
                    'udpxy' in text_lower and any(version in text_lower for version in ['1.0-', '0.', 'prod', 'standard']),
                    '400' in text_lower and 'unrecognized request' in text_lower and 'server:' in text_lower,
                    'server: udpxy' in text_lower,
                    'udpxy' in text_lower,
                ]
                
                is_udpxy = any(udpxy_indicators)
                return is_udpxy
                
            except Exception as e:
                sock.close()
                return False
                
        except Exception as e:
            return False
    
    def get_udpxy_status(self, ip_port, timeout=5):
        """è·å–udpxyçŠ¶æ€é¡µé¢çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æ´»è·ƒè¿æ¥æ•°ï¼‰"""
        try:
            # æ„å»ºçŠ¶æ€é¡µé¢URL
            status_url = f"http://{ip_port}/status"
            
            # åˆ›å»ºsessionè¿›è¡ŒHTTPè¯·æ±‚
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'udpxy-status-checker',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Connection': 'close'
            })
            
            response = session.get(status_url, timeout=timeout)
            response.raise_for_status()
            
            html_content = response.text
            
            # ä½¿ç”¨BeautifulSoupè§£æHTMLé¡µé¢
            if BEAUTIFULSOUP_AVAILABLE:
                try:
                    soup = BeautifulSoup(html_content, "html.parser")
                    
                    # æŸ¥æ‰¾çŠ¶æ€è¡¨æ ¼ (cellspacing='0')
                    client_table = soup.find('table', attrs={'cellspacing': '0'})
                    
                    if client_table:
                        # æ‰¾åˆ°æ‰€æœ‰çš„<td>æ ‡ç­¾
                        td_tags = client_table.find_all('td')
                        
                        if len(td_tags) >= 4:
                            # è·å–çŠ¶æ€ä¿¡æ¯
                            addr = td_tags[2].text.strip() if len(td_tags) > 2 else "N/A"
                            actv = td_tags[3].text.strip() if len(td_tags) > 3 else "0"
                            
                            try:
                                actv_count = int(actv)
                            except ValueError:
                                actv_count = 0
                            
                            status_info = {
                                'address': addr,
                                'active_connections': actv_count,
                                'status_available': True
                            }
                            
                            return status_info
                    else:
                        # æ²¡æœ‰æ‰¾åˆ°æ ‡å‡†æ ¼å¼çš„è¡¨æ ¼ï¼Œå°è¯•å…¶ä»–è§£ææ–¹å¼
                        return self._parse_alternative_status_format(html_content)
                        
                except Exception as e:
                    print(f"  BeautifulSoupè§£æçŠ¶æ€é¡µé¢å¤±è´¥: {e}")
                    return self._parse_status_with_regex(html_content)
            else:
                # å¦‚æœæ²¡æœ‰BeautifulSoupï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ
                return self._parse_status_with_regex(html_content)
            
            # å¦‚æœæ‰€æœ‰è§£ææ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤çŠ¶æ€
            return {
                'address': "N/A",
                'active_connections': 0,
                'status_available': False,
                'error': "æ‰€æœ‰è§£ææ–¹æ³•éƒ½å¤±è´¥"
            }
                
        except requests.exceptions.RequestException as e:
            return {
                'address': "N/A", 
                'active_connections': 0,
                'status_available': False,
                'error': f"è¯·æ±‚å¤±è´¥: {e}"
            }
        except Exception as e:
            return {
                'address': "N/A",
                'active_connections': 0, 
                'status_available': False,
                'error': f"æœªçŸ¥é”™è¯¯: {e}"
            }
    
    def _parse_alternative_status_format(self, html_content):
        """è§£æå…¶ä»–æ ¼å¼çš„udpxyçŠ¶æ€é¡µé¢"""
        try:
            # å°è¯•æŸ¥æ‰¾å¸¸è§çš„çŠ¶æ€ä¿¡æ¯æ¨¡å¼
            import re
            
            # æŸ¥æ‰¾æ´»è·ƒè¿æ¥æ•°çš„æ¨¡å¼
            patterns = [
                r'active[^:]*:\s*(\d+)',
                r'clients[^:]*:\s*(\d+)', 
                r'connections[^:]*:\s*(\d+)',
                r'>(\d+)</td>\s*</tr>\s*</table>',  # è¡¨æ ¼æœ€åä¸€ä¸ªæ•°å­—
            ]
            
            actv_count = 0
            for pattern in patterns:
                match = re.search(pattern, html_content, re.IGNORECASE)
                if match:
                    try:
                        actv_count = int(match.group(1))
                        break
                    except ValueError:
                        continue
            
            return {
                'address': "Alternative Format",
                'active_connections': actv_count,
                'status_available': True
            }
            
        except Exception as e:
            return {
                'address': "N/A",
                'active_connections': 0,
                'status_available': False,
                'error': f"å¤‡ç”¨è§£æå¤±è´¥: {e}"
            }
    
    def _parse_status_with_regex(self, html_content):
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æçŠ¶æ€é¡µé¢ï¼ˆä¸ä¾èµ–BeautifulSoupï¼‰"""
        try:
            import re
            
            # æŸ¥æ‰¾è¡¨æ ¼ä¸­çš„æ•°æ®
            td_pattern = r'<td[^>]*>(.*?)</td>'
            td_matches = re.findall(td_pattern, html_content, re.IGNORECASE | re.DOTALL)
            
            if len(td_matches) >= 4:
                addr = td_matches[2].strip() if len(td_matches) > 2 else "N/A"
                actv_text = td_matches[3].strip() if len(td_matches) > 3 else "0"
                
                # æ¸…ç†HTMLæ ‡ç­¾
                addr = re.sub(r'<[^>]+>', '', addr).strip()
                actv_text = re.sub(r'<[^>]+>', '', actv_text).strip()
                
                try:
                    actv_count = int(actv_text)
                except ValueError:
                    actv_count = 0
                
                return {
                    'address': addr,
                    'active_connections': actv_count,
                    'status_available': True
                }
            
            return {
                'address': "N/A",
                'active_connections': 0,
                'status_available': False,
                'error': "æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¡¨æ ¼æ•°æ®"
            }
            
        except Exception as e:
            return {
                'address': "N/A",
                'active_connections': 0,
                'status_available': False,
                'error': f"æ­£åˆ™è§£æå¤±è´¥: {e}"
            }
    
    def filter_accessible_ips(self, ip_list):
        """è¿‡æ»¤å¯è®¿é—®çš„ IP å¹¶éªŒè¯æ˜¯å¦ä¸ºudpxyæœåŠ¡"""
        print(f"============IPç«¯å£æ£€æµ‹ï¼Œæµ‹è¯• {len(ip_list)} ä¸ª IP==============")
        
        accessible_ips = []
        udpxy_ips = []
        
        def test_single_ip(ip_port):
            # å…ˆæµ‹è¯•ç«¯å£è¿é€šæ€§
            if not self.test_port_connectivity(ip_port):
                return None, False, None
            
            # å†æµ‹è¯•æ˜¯å¦ä¸ºudpxyæœåŠ¡
            is_udpxy = self.test_udpxy_service(ip_port)
            
            # å¦‚æœæ˜¯udpxyæœåŠ¡ï¼Œè·å–çŠ¶æ€ä¿¡æ¯
            status_info = None
            if is_udpxy:
                status_info = self.get_udpxy_status(ip_port)
            
            return ip_port, is_udpxy, status_info
        
        # å¹¶å‘æµ‹è¯•ç«¯å£è¿é€šæ€§å’ŒudpxyæœåŠ¡
        with ThreadPoolExecutor(max_workers=30) as executor:
            futures = [executor.submit(test_single_ip, ip) for ip in ip_list]
            
            for future in as_completed(futures):
                result = future.result()
                if result[0]:  # ç«¯å£å¯è¾¾
                    accessible_ips.append(result[0])
                    print(f"ç«¯å£å¯è¾¾: {result[0]}")
                    
                    if result[1]:  # æ˜¯udpxyæœåŠ¡
                        udpxy_ips.append(result[0])
                        status_info = result[2]  # çŠ¶æ€ä¿¡æ¯
                        
                        if status_info and status_info.get('status_available'):
                            actv = status_info.get('active_connections', 0)
                            addr = status_info.get('address', 'N/A')
                            print(f"  âœ“ udpxyæœåŠ¡: {result[0]} (æ´»è·ƒè¿æ¥: {actv}, åœ°å€: {addr})")
                        else:
                            print(f"  âœ“ udpxyæœåŠ¡: {result[0]} (çŠ¶æ€ä¿¡æ¯ä¸å¯ç”¨)")
                    else:
                        print(f"  âœ— éudpxyæœåŠ¡: {result[0]}")
        
        print(f"===============æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(accessible_ips)} ä¸ªå¯è®¿é—® IPï¼Œ{len(udpxy_ips)} ä¸ªudpxyæœåŠ¡===============")
        
        # ä¿å­˜æ‰€æœ‰å¯è®¿é—®çš„IP
        with open(self.ipfile_sum, 'w') as f:
            for ip in accessible_ips:
                f.write(f"{ip}\n")
        
        # ä¿å­˜udpxyæœåŠ¡IPï¼ˆå»é‡ï¼‰
        unique_udpxy_ips = list(set(udpxy_ips))
        with open(self.ipfile_uniq, 'w') as f:
            for ip in sorted(unique_udpxy_ips):
                f.write(f"{ip}\n")
        
        print(f"ã€{self.ipfile_uniq}ã€‘å†… udpxy IP å…±è®¡ {len(unique_udpxy_ips)} ä¸ª")
        return unique_udpxy_ips
    
    def test_stream_speed(self, ip_port):
        """æµ‹è¯•æµåª’ä½“é€Ÿåº¦ - ç›´æ¥ä¸‹è½½æµåª’ä½“æ•°æ®"""
        session = None
        try:
            # åˆ›å»ºç‹¬ç«‹çš„session
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'FFmpeg/4.4.0',
                'Accept': '*/*',
                'Connection': 'keep-alive'
            })
            
            # è®¾ç½®é€‚é…å™¨
            adapter = HTTPAdapter(
                pool_connections=1,
                pool_maxsize=1,
                max_retries=0
            )
            session.mount('http://', adapter)
            
            # æ„å»ºæµåª’ä½“URL
            stream_url = f"http://{ip_port}/{self.stream}"
            print(f"  æµ‹è¯•æµåª’ä½“: {stream_url}")
            
            # ç›´æ¥ä¸‹è½½æµåª’ä½“æ•°æ®
            start_time = time.time()
            max_download_size = 2 * 1024 * 1024  # 2MBé™åˆ¶
            max_download_time = 10  # æœ€å¤§ä¸‹è½½æ—¶é—´10ç§’
            downloaded_data = b''
            
            try:
                # å‘èµ·æµå¼è¯·æ±‚
                response = session.get(
                    stream_url,
                    timeout=(3, 5),
                    stream=True,
                    allow_redirects=True
                )
                
                if response.status_code != 200:
                    print(f"  ! {ip_port} æµåª’ä½“å“åº”çŠ¶æ€ç : {response.status_code}")
                    return None
                
                print(f"  å¼€å§‹ä¸‹è½½æµåª’ä½“æ•°æ®...")
                
                # æµå¼ä¸‹è½½æ•°æ®
                chunk_count = 0
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        downloaded_data += chunk
                        chunk_count += 1
                        
                        # æ£€æŸ¥é€€å‡ºæ¡ä»¶
                        current_time = time.time()
                        elapsed_time = current_time - start_time
                        current_size = len(downloaded_data)
                        
                        # æ¯æ¥æ”¶åˆ°ä¸€å®šæ•°æ®å°±æ˜¾ç¤ºè¿›åº¦
                        if chunk_count % 50 == 0:
                            current_speed = (current_size / elapsed_time) / 1024 / 1024 if elapsed_time > 0 else 0
                            print(f"    å·²ä¸‹è½½: {current_size/1024:.1f}KB, è€—æ—¶: {elapsed_time:.1f}s, å½“å‰é€Ÿåº¦: {current_speed:.2f}MB/s")
                        
                        # è¶…è¿‡å¤§å°é™åˆ¶
                        if current_size >= max_download_size:
                            print(f"    è¾¾åˆ°å¤§å°é™åˆ¶: {max_download_size/1024/1024}MB")
                            break
                            
                        # è¶…è¿‡æ—¶é—´é™åˆ¶
                        if elapsed_time > max_download_time:
                            print(f"    è¾¾åˆ°æ—¶é—´é™åˆ¶: {max_download_time}ç§’")
                            break
                
                end_time = time.time()
                
            except requests.exceptions.ConnectTimeout:
                print(f"  ! {ip_port} æµåª’ä½“è¿æ¥è¶…æ—¶")
                return None
            except requests.exceptions.ReadTimeout:
                print(f"  ! {ip_port} æµåª’ä½“è¯»å–è¶…æ—¶")
                return None
            except requests.exceptions.ConnectionError as e:
                print(f"  ! {ip_port} æµåª’ä½“è¿æ¥é”™è¯¯: {str(e)[:50]}...")
                return None
            except Exception as e:
                print(f"  ! {ip_port} æµåª’ä½“ä¸‹è½½å¼‚å¸¸: {str(e)[:50]}...")
                return None
            
            # è®¡ç®—ä¸‹è½½ç»Ÿè®¡
            total_size = len(downloaded_data)
            total_duration = end_time - start_time
            
            if total_duration <= 0:
                print(f"  ! {ip_port} ä¸‹è½½æ—¶é—´å¼‚å¸¸: {total_duration}ç§’")
                return None
                
            if total_size == 0:
                print(f"  ! {ip_port} æœªä¸‹è½½åˆ°æ•°æ®ï¼Œå¯èƒ½æµåœ°å€æ— æ•ˆ")
                return None
            
            # æ£€æŸ¥æ˜¯å¦ä¸‹è½½é‡å¤ªå°‘ï¼ˆå¯èƒ½è¿æ¥æœ‰é—®é¢˜ï¼‰
            if total_size < 1024:  # å°äº1KB
                print(f"  ! {ip_port} ä¸‹è½½é‡è¿‡å°‘: {total_size}å­—èŠ‚ï¼Œå¯èƒ½è¿æ¥ä¸ç¨³å®š")
                return None
            
            # è®¡ç®—å¹³å‡é€Ÿåº¦
            speed_bytes_per_sec = total_size / total_duration
            speed_mb_per_sec = speed_bytes_per_sec / 1024 / 1024
            
            # æ£€æŸ¥é€Ÿåº¦åˆç†æ€§
            if speed_mb_per_sec < 0.05:
                print(f"  ! {ip_port} é€Ÿåº¦è¿‡æ…¢: {speed_mb_per_sec:.3f} MB/s")
                return None
            
            if speed_mb_per_sec > 1000:
                print(f"  ! {ip_port} é€Ÿåº¦å¼‚å¸¸: {speed_mb_per_sec:.3f} MB/s")
                return None
            
            print(f"  âœ“ {ip_port} ä¸‹è½½å®Œæˆ:")
            print(f"    æ€»å¤§å°: {total_size/1024:.1f}KB")
            print(f"    æ€»è€—æ—¶: {total_duration:.2f}ç§’") 
            print(f"    å¹³å‡é€Ÿåº¦: {speed_mb_per_sec:.3f}MB/s")
            
            return {
                'ip': ip_port,
                'speed': speed_mb_per_sec,
                'file_size': total_size,
                'duration': total_duration,
                'url': stream_url
            }
            
        except Exception as e:
            print(f"  ! {ip_port} æµ‹é€Ÿå¼‚å¸¸: {str(e)[:100]}...")
            return None
        finally:
            # ç¡®ä¿sessionè¢«æ­£ç¡®å…³é—­
            if session:
                try:
                    session.close()
                except:
                    pass
    
    def run_speed_tests(self, ip_list):
        """è¿è¡Œæµåª’ä½“æµ‹é€Ÿ"""
        print("==========å¼€å§‹æµåª’ä½“æµ‹é€Ÿ=================")
        
        if not ip_list:
            print("æ²¡æœ‰å¯æµ‹è¯•çš„ IP")
            return []
        
        speed_results = []
        error_count = 0
        
        def test_single_stream(index, ip_port):
            try:
                print(f"{index + 1}/{len(ip_list)} æµ‹è¯•udpxyæœåŠ¡: {ip_port}")
                
                # æµ‹è¯•æµåª’ä½“é€Ÿåº¦
                result = self.test_stream_speed(ip_port)
                if result:
                    speed_str = f"{result['speed']:.3f} MB/s"
                    print(f"  âœ“ {ip_port} - é€Ÿåº¦: {speed_str}")
                    
                    # å†™å…¥æ—¥å¿—
                    with open(self.speedtest_log, 'a', encoding='utf-8') as f:
                        f.write(f"{ip_port} {speed_str} Size:{result['file_size']}\n")
                    
                    return result
                else:
                    print(f"  âœ— {ip_port} - æµåª’ä½“æµ‹é€Ÿä¸å¯ç”¨!")
                    return None
            except Exception as e:
                print(f"  âœ— {ip_port} - æµ‹è¯•å¼‚å¸¸: {e}")
                return None
        
        # æ¸…ç©ºä¹‹å‰çš„æ—¥å¿—
        if os.path.exists(self.speedtest_log):
            os.remove(self.speedtest_log)
        
        # å‡å°‘å¹¶å‘æ•°ï¼Œå¢åŠ è¶…æ—¶æ§åˆ¶
        with ThreadPoolExecutor(max_workers=3) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_ip = {
                executor.submit(test_single_stream, i, ip): ip 
                for i, ip in enumerate(ip_list)
            }
            
            # ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶ç­‰å¾…ç»“æœ
            completed_count = 0
            for future in as_completed(future_to_ip, timeout=120):
                try:
                    result = future.result(timeout=15)
                    completed_count += 1
                    
                    if result:
                        speed_results.append(result)
                        print(f"  å®Œæˆä»»åŠ¡ {completed_count}/{len(ip_list)}: é€Ÿåº¦ {result['speed']:.3f} MB/s")
                    else:
                        error_count += 1
                        print(f"  å®Œæˆä»»åŠ¡ {completed_count}/{len(ip_list)}: å¤±è´¥")
                        
                except Exception as e:
                    error_count += 1
                    completed_count += 1
                    ip_port = future_to_ip[future]
                    print(f"  å®Œæˆä»»åŠ¡ {completed_count}/{len(ip_list)}: {ip_port} - ä»»åŠ¡è¶…æ—¶æˆ–å¼‚å¸¸: {e}")
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (completed_count / len(ip_list)) * 100
                print(f"è¿›åº¦: {progress:.1f}% - å¯ç”¨IPï¼š{len(speed_results)} ä¸ª, ä¸å¯ç”¨IPï¼š{error_count} ä¸ª")
        
        print(f"==========æµåª’ä½“æµ‹é€Ÿå®Œæˆ=================")
        print(f"æ€»è®¡: {len(speed_results)} ä¸ªå¯ç”¨IP, {error_count} ä¸ªå¤±è´¥")
        
        return speed_results
    
    def generate_results(self, speed_results):
        """ç”Ÿæˆç»“æœæ–‡ä»¶"""
        if not speed_results:
            print("æœªç”Ÿæˆæµ‹é€Ÿæ–‡ä»¶")
            return
        
        # ç­›é€‰é€Ÿåº¦å¤§äº 0.1 MB/s çš„ç»“æœå¹¶æ’åº
        filtered_results = [r for r in speed_results if r['speed'] > 0.1]
        
        if not filtered_results:
            print("æ²¡æœ‰æ»¡è¶³é€Ÿåº¦è¦æ±‚çš„ IP (>0.1 MB/s)")
            return
        
        # æŒ‰é€Ÿåº¦é™åºæ’åº
        filtered_results.sort(key=lambda x: x['speed'], reverse=True)
        
        # ä¿å­˜ç»“æœ
        with open(self.result_file, 'w', encoding='utf-8') as f:
            for result in filtered_results:
                f.write(f"{result['speed']:.3f}  {result['ip']}\n")
        
        print(f"======æœ¬æ¬¡{self.region}ç»„æ’­IPæœç´¢ç»“æœ=============")
        for result in filtered_results:
            print(f"{result['speed']:.3f} MB/s  {result['ip']}")
        
        # åˆå¹¶æ¨¡æ¿æ–‡ä»¶
        self._merge_template_file(filtered_results)
    
    def _merge_template_file(self, results):
        """åˆå¹¶æ¨¡æ¿æ–‡ä»¶"""
        template_file = Path(f"template/{self.isp}/template_{self.city}.txt")
        output_file = self.output_dir / f"{self.city}.txt"
        
        if not template_file.exists():
            print(f"è­¦å‘Š: æ¨¡æ¿æ–‡ä»¶ {template_file} ä¸å­˜åœ¨ï¼Œè·³è¿‡åˆå¹¶æ­¥éª¤")
            return
        
        print(f"----åˆå¹¶åˆ—è¡¨æ–‡ä»¶åˆ°ï¼š{output_file}---------")
        
        try:
            with open(template_file, 'r', encoding='utf-8') as tf:
                template_content = tf.read()
            
            with open(output_file, 'w', encoding='utf-8') as of:
                for result in results:
                    ip = result['ip']
                    print(f"Processing IP: {ip} (Speed: {result['speed']:.3f} MB/s)")
                    
                    # æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦
                    content = template_content.replace('ipipip', ip)
                    of.write(content)
                    
        except Exception as e:
            print(f"åˆå¹¶æ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
    
    def _save_basic_results(self, udpxy_ips):
        """ä¿å­˜åŸºæœ¬çš„IPæ£€æµ‹ç»“æœï¼ˆä¸è¿›è¡Œæµåª’ä½“æµ‹è¯•æ—¶ä½¿ç”¨ï¼‰"""
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            self.output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜æ‰€æœ‰æ‰¾åˆ°çš„udpxy IPåˆ°sumæ–‡ä»¶
            with open(self.ipfile_sum, 'w', encoding='utf-8') as f:
                for ip in udpxy_ips:
                    # ä¿å­˜å®é™…çš„IP:PORTæ ¼å¼
                    f.write(f"{ip}\n")
            print(f"ä¿å­˜ {len(udpxy_ips)} ä¸ªudpxyæœåŠ¡å™¨åˆ°: {self.ipfile_sum}")
            
            # ä¹Ÿä¿å­˜åˆ°uniqæ–‡ä»¶ï¼ˆå»é‡æ–‡ä»¶ï¼‰
            with open(self.ipfile_uniq, 'w', encoding='utf-8') as f:
                unique_ips = list(set(udpxy_ips))
                for ip in unique_ips:
                    # ä¿å­˜å®é™…çš„IP:PORTæ ¼å¼
                    f.write(f"{ip}\n")
            print(f"ä¿å­˜ {len(unique_ips)} ä¸ªå”¯ä¸€udpxyæœåŠ¡å™¨åˆ°: {self.ipfile_uniq}")
            
            # ä¿å­˜ç®€å•çš„ç»“æœæŠ¥å‘Š
            report_file = self.output_dir / f"{self.city}_basic_report.txt"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(f"UDPXYæœåŠ¡å™¨æœç´¢æŠ¥å‘Š\n")
                f.write(f"åœ°åŒº: {self.region}\n")
                f.write(f"è¿è¥å•†: {self.isp}\n")
                f.write(f"æœç´¢æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ‰¾åˆ°çš„udpxyæœåŠ¡å™¨æ•°é‡: {len(udpxy_ips)}\n")
                f.write(f"å”¯ä¸€æœåŠ¡å™¨æ•°é‡: {len(set(udpxy_ips))}\n")
                f.write(f"\næœåŠ¡å™¨åˆ—è¡¨:\n")
                for ip in udpxy_ips:
                    # ä¿å­˜å®é™…çš„IP:PORTæ ¼å¼
                    f.write(f"{ip}\n")
            print(f"ä¿å­˜åŸºæœ¬æŠ¥å‘Šåˆ°: {report_file}")
            
        except Exception as e:
            print(f"ä¿å­˜åŸºæœ¬ç»“æœå¤±è´¥: {e}")
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        temp_files = [
            self.speedtest_log,
            "temp_video.mp4",
            "ffmpeg.log"
        ]
        
        for file_path in temp_files:
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file_path}")
    
    def run(self):
        """è¿è¡Œå®Œæ•´çš„æµ‹è¯•æµç¨‹"""
        try:
            print(f"å¼€å§‹ä¸º {self.region} {self.isp} æœç´¢å’Œæµ‹è¯• IP")
            if not self.notest:
                print(f"åŸå¸‚: {self.city}, æµåœ°å€: {self.stream}")
            else:
                print("è·³è¿‡æµåª’ä½“æµ‹è¯•æ¨¡å¼")
            
            # 1. æœç´¢ IP
            fofa_ips = self.search_fofa_ips()
            quake_ips = self.search_quake360_ips()
            
            # åˆå¹¶å¹¶å»é‡
            all_ips = list(set(fofa_ips + quake_ips))
            print(f"ä»FOFAå’ŒQuake360æ€»å…±æ‰¾åˆ° {len(all_ips)} ä¸ªå”¯ä¸€ IP")
            
            if not all_ips:
                print("æœªæ‰¾åˆ°ä»»ä½• IPï¼Œç¨‹åºé€€å‡º")
                return
            
            print(f"æ€»å…±å°†æµ‹è¯• {len(all_ips)} ä¸ª IP")
            
            # 2. è¿‡æ»¤å¯è®¿é—®çš„ IP å¹¶éªŒè¯udpxyæœåŠ¡
            udpxy_ips = self.filter_accessible_ips(all_ips)
            
            if not udpxy_ips:
                print("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„udpxyæœåŠ¡å™¨ï¼Œç¨‹åºé€€å‡º")
                return
            
            if self.notest:
                # åªè¿›è¡ŒIPæœç´¢å’Œç«¯å£æ£€æµ‹ï¼Œä¸è¿›è¡Œæµåª’ä½“æµ‹è¯•
                print(f"å‘ç° {len(udpxy_ips)} ä¸ªå¯ç”¨çš„udpxyæœåŠ¡å™¨")
                print("è·³è¿‡æµåª’ä½“æµ‹è¯•å’Œæ¨¡æ¿ç”Ÿæˆ")
                
                # ä¿å­˜åŸºæœ¬ç»“æœ
                self._save_basic_results(udpxy_ips)
                print("-----------------æœç´¢å®Œæˆ----------------")
            else:
                # 3. è¿è¡Œé€Ÿåº¦æµ‹è¯•ï¼ˆåªæµ‹è¯•udpxyæœåŠ¡å™¨ï¼‰
                speed_results = self.run_speed_tests(udpxy_ips)
                
                # 4. ç”Ÿæˆç»“æœ
                self.generate_results(speed_results)
                
                print("-----------------æµ‹é€Ÿå®Œæˆ----------------")
            
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
        except Exception as e:
            print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        finally:
            # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self.cleanup()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='IPTV IP æœç´¢ä¸æµ‹é€Ÿç»¼åˆå·¥å…· - æ–°ç‰ˆæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python speedtest_integrated_new.py Shanghai Telecom
  python speedtest_integrated_new.py Beijing Unicom
  python speedtest_integrated_new.py Guangzhou Mobile
  python speedtest_integrated_new.py Shanghai Telecom --max-pages 5
  python speedtest_integrated_new.py Beijing Mobile --notest

è¿è¥å•†å¯é€‰: Telecom, Unicom, Mobile

å‚æ•°è¯´æ˜:
  --max-pages: é™åˆ¶æœç´¢çš„æœ€å¤§é¡µæ•°
  --notest: è·³è¿‡æµåª’ä½“æµ‹è¯•ï¼Œä»…è¿›è¡ŒIPæœç´¢å’Œç«¯å£æ£€æµ‹
        """
    )
    
    parser.add_argument('region', help='çœå¸‚åç§° (å¦‚: Shanghai, Beijing)')
    parser.add_argument('isp', help='è¿è¥å•† (Telecom/Unicom/Mobile)')
    parser.add_argument('--max-pages', type=int, default=10, 
                       help='æœ€å¤§ç¿»é¡µæ•°é™åˆ¶ (é»˜è®¤: 10é¡µ)')
    parser.add_argument('--notest', action='store_true',
                       help='è·³è¿‡æµåª’ä½“æµ‹è¯•å’Œæ¨¡æ¿ç”Ÿæˆï¼Œä»…è¿›è¡ŒIPæœç´¢å’Œç«¯å£æ£€æµ‹')
    
    args = parser.parse_args()
    
    # éªŒè¯è¿è¥å•†å‚æ•°
    valid_isps = ['telecom', 'unicom', 'mobile']
    if args.isp.lower() not in valid_isps:
        print(f"é”™è¯¯: ä¸æ”¯æŒçš„è¿è¥å•† '{args.isp}'")
        print(f"æ”¯æŒçš„è¿è¥å•†: {', '.join(valid_isps)}")
        sys.exit(1)
    
    # éªŒè¯æœ€å¤§é¡µæ•°å‚æ•°
    if args.max_pages < 1:
        print(f"é”™è¯¯: æœ€å¤§é¡µæ•°å¿…é¡»å¤§äº0ï¼Œå½“å‰å€¼: {args.max_pages}")
        sys.exit(1)
    
    if args.max_pages > 50:
        print(f"è­¦å‘Š: æœ€å¤§é¡µæ•°è¿‡å¤§({args.max_pages})ï¼Œå»ºè®®ä¸è¶…è¿‡50é¡µ")
        response = input("æ˜¯å¦ç»§ç»­? (y/N): ")
        if response.lower() != 'y':
            print("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            sys.exit(0)
    
    print(f"é…ç½®ä¿¡æ¯:")
    print(f"  åœ°åŒº: {args.region}")
    print(f"  è¿è¥å•†: {args.isp}")
    print(f"  æœ€å¤§ç¿»é¡µæ•°: {args.max_pages}")
    if args.notest:
        print(f"  æ¨¡å¼: ä»…æœç´¢æ¨¡å¼ï¼ˆè·³è¿‡æµåª’ä½“æµ‹è¯•ï¼‰")
    else:
        print(f"  æ¨¡å¼: å®Œæ•´æµ‹è¯•æ¨¡å¼")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹å¹¶è¿è¡Œ
    speedtest = IPTVSpeedTest(args.region, args.isp, args.max_pages, args.notest)
    speedtest.run()


if __name__ == "__main__":
    main()
