#!/usr/bin/env python3
"""
IPTVç›´æ’­æºä¸‹è½½ã€åˆå¹¶ã€æµ‹é€Ÿä¸åˆ†ç»„å·¥å…·

åŠŸèƒ½ï¼š
1. ä»æŒ‡å®šURLåˆ—è¡¨ä¸‹è½½ç›´æ’­æºtxtæ–‡ä»¶
2. åˆå¹¶æ‰€æœ‰é¢‘é“ï¼ˆå¿½ç•¥åŸåˆ†ç»„ï¼‰
3. å¯¹æµåª’ä½“åœ°å€è¿›è¡Œæµ‹é€Ÿ
4. æŒ‰é€Ÿåº¦æ’åºå¹¶ä¿ç•™å‰Nä¸ª
5. é‡æ–°åˆ†ç»„å¹¶ç”Ÿæˆç»“æœæ–‡ä»¶

ç”¨æ³•ï¼š
python unicast.py --top 20
python unicast.py --top 20 --proxy http://127.0.0.1:10808

é¡¹ç›®ä¸»é¡µ: https://github.com/vitter/iptv-sources
é—®é¢˜åé¦ˆ: https://github.com/vitter/iptv-sources/issues
"""

import os
import re
import sys
import time
import socket
import argparse
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Tuple
from dataclasses import dataclass
from pathlib import Path


def load_env_file(env_path=".env"):
    """åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼Œæ”¯æŒå¤šè¡Œå€¼"""
    if os.path.exists(env_path):
        with open(env_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æç¯å¢ƒå˜é‡ï¼Œæ”¯æŒå¤šè¡Œå€¼
        pattern = r'^([A-Z_][A-Z0-9_]*)=(.*)$'
        lines = content.split('\n')
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            if line and not line.startswith('#') and '=' in line:
                match = re.match(pattern, line)
                if match:
                    key = match.group(1)
                    value = match.group(2)
                    
                    # å¤„ç†å¼•å·åŒ…å›´çš„å¤šè¡Œå€¼
                    if value.startswith('"') and not value.endswith('"'):
                        # å¤šè¡Œå€¼ï¼Œç»§ç»­è¯»å–ç›´åˆ°æ‰¾åˆ°ç»“æŸå¼•å·
                        i += 1
                        while i < len(lines):
                            next_line = lines[i]
                            value += '\n' + next_line
                            if next_line.rstrip().endswith('"'):
                                break
                            i += 1
                    
                    # ç§»é™¤é¦–å°¾å¼•å·
                    value = value.strip().strip('"').strip("'")
                    os.environ[key] = value
            i += 1


def load_urls_from_env():
    """ä»ç¯å¢ƒå˜é‡åŠ è½½URLåˆ—è¡¨é˜²æ­¢æœ‰äººæ‹¿èµ°ä»£ç ä¸æ³¨æ˜å‡ºå¤„ä¸æ„Ÿè°¢å°±ç›´æ¥ä½¿ç”¨"""
    urls_env = os.getenv('IPTV_URLS', '')
    if urls_env:
        # æ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼šæ¢è¡Œç¬¦ã€é€—å·ã€åˆ†å·
        urls = []
        for url in re.split(r'[,;\n]+', urls_env):
            url = url.strip()
            if url:
                urls.append(url)
        return urls
    return None


@dataclass
class ChannelInfo:
    """é¢‘é“ä¿¡æ¯"""
    name: str
    url: str
    speed: float = 0.0


class ChannelGroup:
    """é¢‘é“åˆ†ç»„æšä¸¾ç±»"""
    CCTV = "å¤®è§†é¢‘é“"
    WEI_SHI = "å«è§†é¢‘é“"
    LOCAL = "çœçº§é¢‘é“"
    HKMOTW = "æ¸¯æ¾³å°é¢‘é“"
    CITY = "å¸‚çº§é¢‘é“"
    OTHER = "å…¶å®ƒé¢‘é“"


class UnicastProcessor:
    """IPTVç›´æ’­æºå¤„ç†å™¨"""
    
    # é»˜è®¤URLåˆ—è¡¨ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
    DEFAULT_URLS = [
        "https://live.zbds.org/tv/yd.txt",
        "https://chinaiptv.pages.dev/Unicast/anhui/mobile.txt"
    ]
    
    # åˆ†ç»„å…³é”®å­—
    locals = ("åŒ—äº¬", "å¤©æ´¥", "ä¸Šæµ·", "é‡åº†", "æ²³åŒ—", "å±±è¥¿", "è¾½å®", "å‰æ—", "é»‘é¾™æ±Ÿ", 
              "æ±Ÿè‹", "æµ™æ±Ÿ", "å®‰å¾½", "ç¦å»º", "æ±Ÿè¥¿", "å±±ä¸œ", "æ²³å—", "æ¹–åŒ—", "æ¹–å—", 
              "å¹¿ä¸œ", "æµ·å—", "å››å·", "è´µå·", "äº‘å—", "é™•è¥¿", "ç”˜è‚ƒ", "é’æµ·", "å†…è’™", 
              "å¹¿è¥¿", "è¥¿è—", "å®å¤", "æ–°ç–†", "ä¸œå—", "ä¸œæ–¹")
    
    hkmotw = ("å‡¤å‡°", "é¦™æ¸¯", "TVB", "tvb", "RTHK", "æ¸¯å°", "æ˜ç ", "ç¿¡ç¿ ", "é¢åŒ…", "äººé—´", "å”¯å¿ƒ", "æ˜Ÿç©º", "æ— çº¿", "æœ‰çº¿", "æ— çº¿ç”µè§†", "æ— çº¿æ–°é—»", "æ— çº¿å¨±ä¹", "å¤§çˆ±", "ç•ªè–¯", "äºšæ´²", "åè§†", "ä¸­å¤©", "ä¸­è§†", "æ°‘è§†", "ä¸œæ£®", "ä¸‰ç«‹", "å°è§†", "å…¬è§†", "å°æ¹¾","æ¾³é—¨", "æ¾³è§†", "æ¾³äºš", "æ¾³å¹¿")
    
    wei_shi = ("å«è§†",)
    
    citys = ("çŸ³å®¶åº„", "å”å±±", "ç§¦çš‡å²›", "é‚¯éƒ¸", "é‚¢å°", "ä¿å®š", "å¼ å®¶å£", "æ‰¿å¾·", "æ²§å·", "å»ŠåŠ", "è¡¡æ°´",
"å¤ªåŸ", "å¤§åŒ", "é˜³æ³‰", "é•¿æ²»", "æ™‹åŸ", "æœ”å·", "æ™‹ä¸­", "è¿åŸ", "å¿»å·", "ä¸´æ±¾", "å•æ¢",
"å‘¼å’Œæµ©ç‰¹", "åŒ…å¤´", "ä¹Œæµ·", "èµ¤å³°", "é€šè¾½", "é„‚å°”å¤šæ–¯", "å‘¼ä¼¦è´å°”", "å·´å½¦æ·–å°”", "ä¹Œå…°å¯Ÿå¸ƒ",
"æ²ˆé˜³", "å¤§è¿", "éå±±", "æŠšé¡º", "æœ¬æºª", "ä¸¹ä¸œ", "é”¦å·", "è¥å£", "é˜œæ–°", "è¾½é˜³", "ç›˜é”¦", "é“å²­", "æœé˜³", "è‘«èŠ¦å²›",
"é•¿æ˜¥", "å‰æ—", "å››å¹³", "è¾½æº", "é€šåŒ–", "ç™½å±±", "æ¾åŸ", "ç™½åŸ", "å»¶è¾¹æœé²œæ—è‡ªæ²»å·",
"å“ˆå°”æ»¨", "é½é½å“ˆå°”", "é¸¡è¥¿", "é¹¤å²—", "åŒé¸­å±±", "å¤§åº†", "ä¼Šæ˜¥", "ä½³æœ¨æ–¯", "ä¸ƒå°æ²³", "ç‰¡ä¸¹æ±Ÿ", "é»‘æ²³", "ç»¥åŒ–", "å¤§å…´å®‰å²­åœ°åŒº",
"å—äº¬", "æ— é”¡", "å¾å·", "å¸¸å·", "è‹å·", "å—é€š", "è¿äº‘æ¸¯", "æ·®å®‰", "ç›åŸ", "æ‰¬å·", "é•‡æ±Ÿ", "æ³°å·", "å®¿è¿",
"æ­å·", "å®æ³¢", "æ¸©å·", "å˜‰å…´", "æ¹–å·", "ç»å…´", "é‡‘å", "è¡¢å·", "èˆŸå±±", "å°å·", "ä¸½æ°´",
"åˆè‚¥", "èŠœæ¹–", "èšŒåŸ ", "æ·®å—", "é©¬éå±±", "æ·®åŒ—", "é“œé™µ", "å®‰åº†", "é»„å±±", "æ»å·", "é˜œé˜³", "å®¿å·", "å…­å®‰", "äº³å·", "æ± å·", "å®£åŸ",
"ç¦å·", "å¦é—¨", "è†ç”°", "ä¸‰æ˜", "æ³‰å·", "æ¼³å·", "å—å¹³", "é¾™å²©", "å®å¾·",
"å—æ˜Œ", "æ™¯å¾·é•‡", "èä¹¡", "ä¹æ±Ÿ", "æ–°ä½™", "é¹°æ½­", "èµ£å·", "å‰å®‰", "å®œæ˜¥", "æŠšå·", "ä¸Šé¥¶",
"æµå—", "é’å²›", "æ·„åš", "æ£åº„", "ä¸œè¥", "çƒŸå°", "æ½åŠ", "æµå®", "æ³°å®‰", "å¨æµ·", "æ—¥ç…§", "ä¸´æ²‚", "å¾·å·", "èŠåŸ", "æ»¨å·", "èæ³½",
"éƒ‘å·", "å¼€å°", "æ´›é˜³", "å¹³é¡¶å±±", "å®‰é˜³", "é¹¤å£", "æ–°ä¹¡", "ç„¦ä½œ", "æ¿®é˜³", "è®¸æ˜Œ", "æ¼¯æ²³", "ä¸‰é—¨å³¡", "å—é˜³", "å•†ä¸˜", "ä¿¡é˜³", "å‘¨å£", "é©»é©¬åº—",
"æ­¦æ±‰", "é»„çŸ³", "åå °", "å®œæ˜Œ", "è¥„é˜³", "é„‚å·", "è†é—¨", "å­æ„Ÿ", "è†å·", "é»„å†ˆ", "å’¸å®", "éšå·", "æ©æ–½åœŸå®¶æ—è‹—æ—è‡ªæ²»å·",
"é•¿æ²™", "æ ªæ´²", "æ¹˜æ½­", "è¡¡é˜³", "é‚µé˜³", "å²³é˜³", "å¸¸å¾·", "å¼ å®¶ç•Œ", "ç›Šé˜³", "éƒ´å·", "æ°¸å·", "æ€€åŒ–", "å¨„åº•", "æ¹˜è¥¿åœŸå®¶æ—è‹—æ—è‡ªæ²»å·",
"å¹¿å·", "éŸ¶å…³", "æ·±åœ³", "ç æµ·", "æ±•å¤´", "ä½›å±±", "æ±Ÿé—¨", "æ¹›æ±Ÿ", "èŒ‚å", "è‚‡åº†", "æƒ å·", "æ¢…å·", "æ±•å°¾", "æ²³æº", "é˜³æ±Ÿ", "æ¸…è¿œ", "ä¸œè", "ä¸­å±±", "æ½®å·", "æ­é˜³", "äº‘æµ®",
"å—å®", "æŸ³å·", "æ¡‚æ—", "æ¢§å·", "åŒ—æµ·", "é˜²åŸæ¸¯", "é’¦å·", "è´µæ¸¯", "ç‰æ—", "ç™¾è‰²", "è´ºå·", "æ²³æ± ", "æ¥å®¾", "å´‡å·¦",
"æµ·å£", "ä¸‰äºš", "ä¸‰æ²™", "å„‹å·",
"é‡åº†",
"æˆéƒ½", "è‡ªè´¡", "æ”€æèŠ±", "æ³¸å·", "å¾·é˜³", "ç»µé˜³", "å¹¿å…ƒ", "é‚å®", "å†…æ±Ÿ", "ä¹å±±", "å—å……", "çœ‰å±±", "å®œå®¾", "å¹¿å®‰", "è¾¾å·", "é›…å®‰", "å·´ä¸­", "èµ„é˜³", "é˜¿åè—æ—ç¾Œæ—è‡ªæ²»å·", "ç”˜å­œè—æ—è‡ªæ²»å·", "å‡‰å±±å½æ—è‡ªæ²»å·",
"è´µé˜³", "å…­ç›˜æ°´", "éµä¹‰", "å®‰é¡º", "æ¯•èŠ‚", "é“œä»", "é»”ä¸œå—è‹—æ—ä¾—æ—è‡ªæ²»å·", "é»”å—å¸ƒä¾æ—è‹—æ—è‡ªæ²»å·", "é»”è¥¿å—å¸ƒä¾æ—è‹—æ—è‡ªæ²»å·",
"æ˜†æ˜", "æ›²é–", "ç‰æºª", "ä¿å±±", "æ˜­é€š", "ä¸½æ±Ÿ", "æ™®æ´±", "ä¸´æ²§", "æ¥šé›„å½æ—è‡ªæ²»å·", "çº¢æ²³å“ˆå°¼æ—å½æ—è‡ªæ²»å·", "æ–‡å±±å£®æ—è‹—æ—è‡ªæ²»å·", "è¥¿åŒç‰ˆçº³å‚£æ—è‡ªæ²»å·", "å¤§ç†ç™½æ—è‡ªæ²»å·", "å¾·å®å‚£æ—æ™¯é¢‡æ—è‡ªæ²»å·", "æ€’æ±Ÿå‚ˆåƒ³æ—è‡ªæ²»å·", "è¿ªåº†è—æ—è‡ªæ²»å·",
"æ‹‰è¨", "æ—¥å–€åˆ™", "æ˜Œéƒ½", "æ—èŠ", "å±±å—", "é‚£æ›²", "é˜¿é‡Œåœ°åŒº",
"è¥¿å®‰", "é“œå·", "å®é¸¡", "å’¸é˜³", "æ¸­å—", "å»¶å®‰", "æ±‰ä¸­", "æ¦†æ—", "å®‰åº·", "å•†æ´›",
"å…°å·", "å˜‰å³ªå…³", "é‡‘æ˜Œ", "ç™½é“¶", "å¤©æ°´", "æ­¦å¨", "å¼ æ–", "å¹³å‡‰", "é…’æ³‰", "åº†é˜³", "å®šè¥¿", "é™‡å—", "ä¸´å¤å›æ—è‡ªæ²»å·", "ç”˜å—è—æ—è‡ªæ²»å·",
"è¥¿å®", "æµ·ä¸œ", "æµ·åŒ—è—æ—è‡ªæ²»å·", "é»„å—è—æ—è‡ªæ²»å·", "æµ·å—è—æ—è‡ªæ²»å·", "æœæ´›è—æ—è‡ªæ²»å·", "ç‰æ ‘è—æ—è‡ªæ²»å·", "æµ·è¥¿è’™å¤æ—è—æ—è‡ªæ²»å·",
"é“¶å·", "çŸ³å˜´å±±", "å´å¿ ", "å›ºåŸ", "ä¸­å«",
"ä¹Œé²æœ¨é½", "å…‹æ‹‰ç›ä¾", "åé²ç•ª", "å“ˆå¯†", "æ˜Œå‰å›æ—è‡ªæ²»å·", "åšå°”å¡”æ‹‰è’™å¤è‡ªæ²»å·", "å·´éŸ³éƒ­æ¥è’™å¤è‡ªæ²»å·", "é˜¿å…‹è‹åœ°åŒº", "å…‹å­œå‹’è‹æŸ¯å°”å…‹å­œè‡ªæ²»å·", "å–€ä»€åœ°åŒº", "å’Œç”°åœ°åŒº", "ä¼ŠçŠå“ˆè¨å…‹è‡ªæ²»å·", "å¡”åŸåœ°åŒº", "é˜¿å‹’æ³°åœ°åŒº")
    
    def __init__(self, top_count=20, proxy=None):
        self.top_count = top_count
        self.proxy = proxy
        self.download_dir = Path("downloads")
        self.output_dir = Path("output")
        self.temp_file = Path("txt.tmp")  # æ±‡æ€»ä¸´æ—¶æ–‡ä»¶
        self.speed_log = Path("speed.log")  # æµ‹é€Ÿæ—¥å¿—æ–‡ä»¶
        
        # åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶
        load_env_file()
        
        # ä»ç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨é»˜è®¤URLåˆ—è¡¨
        env_urls = load_urls_from_env()
        if env_urls:
            self.URLS = env_urls
            print(f"âœ“ ä»ç¯å¢ƒå˜é‡åŠ è½½äº† {len(env_urls)} ä¸ªURL")
        else:
            self.URLS = self.DEFAULT_URLS
            print(f"! æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡IPTV_URLSï¼Œä½¿ç”¨é»˜è®¤çš„ {len(self.DEFAULT_URLS)} ä¸ªURL")
            
        self._create_directories()
        
    def _create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        self.download_dir.mkdir(exist_ok=True)
        self.output_dir.mkdir(exist_ok=True)
        
    def download_files(self):
        """ä¸‹è½½æ‰€æœ‰txtæ–‡ä»¶"""
        print("å¼€å§‹ä¸‹è½½ç›´æ’­æºæ–‡ä»¶...")
        if self.proxy:
            print(f"ä½¿ç”¨ä»£ç†: {self.proxy}")
        
        def download_single_file(url):
            try:
                # è§£æURLç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
                filename = self._generate_unique_filename(url)
                filepath = self.download_dir / filename
                
                # è®¾ç½®ä»£ç†
                proxies = {}
                if self.proxy:
                    proxies = {
                        'http': self.proxy,
                        'https': self.proxy
                    }
                
                print(f"â³ æ­£åœ¨ä¸‹è½½: {url}")
                response = requests.get(url, timeout=15, proxies=proxies, headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                })
                response.raise_for_status()
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(response.text)
                    
                print(f"âœ“ ä¸‹è½½æˆåŠŸ: {filename}")
                return filepath
                
            except requests.exceptions.Timeout:
                print(f"âœ— ä¸‹è½½è¶…æ—¶: {url}")
                return None
            except requests.exceptions.ConnectionError:
                print(f"âœ— è¿æ¥å¤±è´¥: {url}")
                return None
            except requests.exceptions.HTTPError as e:
                print(f"âœ— HTTPé”™è¯¯ {e.response.status_code}: {url}")
                return None
            except Exception as e:
                print(f"âœ— ä¸‹è½½å¤±è´¥ {url}: {e}")
                return None
        
        # å‡å°‘å¹¶å‘æ•°é‡ï¼Œé¿å…ç½‘ç»œæ‹¥å µ
        downloaded_files = []
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(download_single_file, url) for url in self.URLS]
            for future in as_completed(futures):
                result = future.result()
                if result:
                    downloaded_files.append(result)
        
        print(f"ä¸‹è½½å®Œæˆï¼Œå…±è·å¾— {len(downloaded_files)} ä¸ªæ–‡ä»¶ï¼Œå¤±è´¥ {len(self.URLS) - len(downloaded_files)} ä¸ª")
        return downloaded_files
        return downloaded_files
    
    def _generate_unique_filename(self, url):
        """æ ¹æ®URLç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å"""
        from urllib.parse import urlparse
        
        parsed = urlparse(url)
        path_parts = [part for part in parsed.path.split('/') if part]
        
        # è·å–åŸå§‹æ–‡ä»¶å
        original_filename = path_parts[-1] if path_parts else "unknown.txt"
        
        # å¦‚æœæ²¡æœ‰.txtæ‰©å±•åï¼Œæ·»åŠ å®ƒ
        if not original_filename.endswith('.txt'):
            original_filename = f"{original_filename}.txt"
        
        # ç”Ÿæˆå‰ç¼€ï¼šä½¿ç”¨åŸŸåå’Œè·¯å¾„
        domain = parsed.netloc.replace('.', '_')
        
        # å¦‚æœè·¯å¾„æœ‰å¤šä¸ªéƒ¨åˆ†ï¼Œä½¿ç”¨å€’æ•°ç¬¬äºŒä¸ªä½œä¸ºå‰ç¼€
        if len(path_parts) > 1:
            prefix = path_parts[-2]  # ä½¿ç”¨ç›®å½•åä½œä¸ºå‰ç¼€
        else:
            prefix = domain.split('_')[0]  # ä½¿ç”¨åŸŸåç¬¬ä¸€éƒ¨åˆ†
        
        # ç»„åˆç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        name_without_ext = original_filename.rsplit('.', 1)[0]
        unique_filename = f"{prefix}_{name_without_ext}.txt"
        
        return unique_filename
    
    def parse_txt_files(self, filepaths):
        """è§£ætxtæ–‡ä»¶å¹¶æå–é¢‘é“ä¿¡æ¯"""
        print("è§£æç›´æ’­æºæ–‡ä»¶...")
        all_channels = []
        all_content = []  # æ”¶é›†æ‰€æœ‰æ–‡ä»¶å†…å®¹ç”¨äºåˆå¹¶
        
        for filepath in filepaths:
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                all_content.append(f"# æ¥æºæ–‡ä»¶: {filepath.name}\n{content}\n")
                
                channels = self._parse_content(content)
                all_channels.extend(channels)
                print(f"âœ“ è§£æ {filepath.name}: è·å¾— {len(channels)} ä¸ªé¢‘é“")
                
            except Exception as e:
                print(f"âœ— è§£æå¤±è´¥ {filepath}: {e}")
        
        # ç”Ÿæˆæ±‡æ€»ä¸´æ—¶æ–‡ä»¶
        self._create_merged_temp_file(all_content)
        
        print(f"æ€»å…±è§£æå‡º {len(all_channels)} ä¸ªé¢‘é“")
        return all_channels
    
    def _create_merged_temp_file(self, all_content):
        """åˆ›å»ºåˆå¹¶çš„ä¸´æ—¶æ–‡ä»¶"""
        try:
            with open(self.temp_file, 'w', encoding='utf-8') as f:
                f.write("# IPTVç›´æ’­æºæ±‡æ€»ä¸´æ—¶æ–‡ä»¶\n")
                f.write(f"# ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.writelines(all_content)
            
            print(f"âœ“ æ±‡æ€»ä¸´æ—¶æ–‡ä»¶å·²ç”Ÿæˆ: {self.temp_file}")
            
        except Exception as e:
            print(f"âœ— ç”Ÿæˆæ±‡æ€»ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    def _parse_content(self, content):
        """è§£ætxtå†…å®¹æå–é¢‘é“ä¿¡æ¯"""
        channels = []
        lines = [line.strip() for line in content.split('\n') if line.strip()]
        
        for line in lines:
            # è·³è¿‡åˆ†ç»„è¡Œ
            if line.endswith('#genre#'):
                continue
                
            # è§£æé¢‘é“è¡Œï¼šé¢‘é“å,urlæˆ–url1#url2#url3
            if ',' in line:
                parts = line.split(',', 1)
                if len(parts) == 2:
                    name = parts[0].strip()
                    url_part = parts[1].strip()
                    
                    # ç»Ÿä¸€é¢‘é“åç§°æ ¼å¼ï¼šå°†CCTV-1ç»Ÿä¸€ä¸ºCCTV1
                    name = self._normalize_channel_name(name)
                    
                    # å¤„ç†å¤šä¸ªURLç”¨#åˆ†éš”çš„æƒ…å†µ
                    urls = [url.strip() for url in url_part.split('#') if url.strip()]
                    
                    # ä¸ºæ¯ä¸ªURLåˆ›å»ºé¢‘é“æ¡ç›®
                    for url in urls:
                        if url and url.startswith('http'):
                            channels.append(ChannelInfo(name, url))
        
        return channels
    
    def _normalize_channel_name(self, name):
        """ç»Ÿä¸€é¢‘é“åç§°æ ¼å¼"""
        # 1. å…ˆè½¬æ¢ä¸ºå¤§å†™
        name = name.upper()
        
        # 2. æŒ‰é¡ºåºåˆ é™¤æŒ‡å®šå­—ç¬¦å’Œå†…å®¹
        remove_patterns = [
            r'\s+',  # ç©ºæ ¼
            r'-',    # è¿å­—ç¬¦
            r'\*',   # æ˜Ÿå·
            r'é¢‘é“',
            r'é«˜æ¸…æµ‹è¯•',
            r'è¶…é«˜æ¸…',
            r'é«˜æ¸…',
            r'æ ‡æ¸…',
            r'UD',
            r'è¶…æ¸…',
            r'\(è¯•ç”¨\)',
            r'\(æµ‹è¯•\)',
            r'\(è¯•çœ‹\)',
            r'\(576P\)',
            r'\(720P\)',
            r'\(1080P\)',
            r'ã€',
            r'ã€',
            r'ï½œ',
            r'\(',
            r'\)',
            r'10M',
            r'12M',
            r'17M',
            r'22M',
            r'1M',
            r'2M',
            r'3M',
            r'7\.5M',
            r'3\.5M',
            r'4M',
            r'5M',
            r'6M',
            r'7M',
            r'8M',
            r'9M',
            r'576',
            r'720',
            r'1920X1080',
            r'1080',
            r'2160',
            r'50P',
            r'HEVC',
            r'HDR',
            r'CHD',
            r'HD',
            r'NEWTV',
            r'SITV',
            r'IHOT',
            r'HOT',
            r'UTV',
            r'NNM',
            r'IPTV',
            r'IPV6'
        ]
        
        for pattern in remove_patterns:
            name = re.sub(pattern, '', name)
        
        # 3. ç°æœ‰çš„CCTVå’ŒCGTNè§„åˆ™
        # å°†CCTV-1ç»Ÿä¸€ä¸ºCCTV1ï¼ŒCGTN-è‹±è¯­ç»Ÿä¸€ä¸ºCGTNè‹±è¯­ç­‰
        name = re.sub(r'CCTV-?(\d+)', r'CCTV\1', name)
        name = re.sub(r'CGTN-?(\w+)', r'CGTN\1', name)
        
        # CCTVé¢‘é“ç‰¹æ®Šå¤„ç†ï¼šé™¤äº†CCTV5+ï¼Œå…¶ä»–CCTVé¢‘é“å»é™¤+ã€-ã€ç©ºæ ¼ã€*ç¬¦å·
        if re.match(r'CCTV', name):
            # ä¿æŠ¤CCTV5+ä¸è¢«ä¿®æ”¹
            if not re.match(r'CCTV5\+', name):
                # å»é™¤+ã€-ã€ç©ºæ ¼ã€*ç¬¦å·
                name = re.sub(r'[+\-\s*]', '', name)
        
        # 4. å¤„ç†CCTVæ•°å­—åçš„æ–‡å­—è¯´æ˜
        cctv_replacements = {
            r'CCTV1ç»¼åˆ': 'CCTV1',
            r'CCTV2è´¢ç»': 'CCTV2',
            r'CCTV3ç»¼è‰º': 'CCTV3',
            r'CCTV4ä¸­æ–‡å›½é™…': 'CCTV4',
            r'CCTV5ä½“è‚²': 'CCTV5',
            r'CCTV5\+ä½“è‚²èµ›äº‹': 'CCTV5+',  # ç‰¹æ®Šä¿ç•™5+
            r'CCTV6ç”µå½±': 'CCTV6',
            r'CCTV7å›½é˜²å†›äº‹': 'CCTV7',
            r'CCTV8ç”µè§†å‰§': 'CCTV8',
            r'CCTV9çºªå½•': 'CCTV9',
            r'CCTV9ä¸­æ–‡': 'CCTV9',
            r'CCTV10ç§‘æ•™': 'CCTV10',
            r'CCTV11æˆæ›²': 'CCTV11',
            r'CCTV12ç¤¾ä¼šä¸æ³•': 'CCTV12',
            r'CCTV13æ–°é—»': 'CCTV13',
            r'CCTV14å°‘å„¿': 'CCTV14',
            r'CCTVå°‘å„¿': 'CCTV14',
            r'CCTV15éŸ³ä¹': 'CCTV15',
            r'CCTV16å¥¥æ—åŒ¹å…‹': 'CCTV16',
            r'CCTV164K': 'CCTV16',
            r'CCTV4Kæµ‹è¯•': 'CCTV4K',
            r'CCTV17å†œä¸šå†œæ‘': 'CCTV17',
            r'CGTN1': 'CGTN',
            r'CGTN2': 'CGTNçºªå½•',
            r'CGTNè®°å½•': 'CGTNçºªå½•',
            r'CGTNè¥¿ç­ç‰™è¯­': 'CGTNè¥¿è¯­',
            r'CGTNçºªå½•ç‰‡': 'CGTNçºªå½•',
            r'CGTNé˜¿æ‹‰ä¼¯è¯­': 'CGTNé˜¿è¯­',
            r'CGTNä¿„ç½—æ–¯è¯­': 'CGTNä¿„è¯­',
            r'CGTNæ–°é—»': 'CGTN',
            r'CGTNè‹±è¯­è®°å½•': 'CGTNçºªå½•',
            r'CGTNè‹±è¯­': 'CGTN',
            r'CGTNè‹±æ–‡è®°å½•': 'CGTNçºªå½•'
        }
        
        for pattern, replacement in cctv_replacements.items():
            name = re.sub(pattern, replacement, name)
        
        return name
    
    def _create_streaming_session(self):
        """åˆ›å»ºé’ˆå¯¹æµåª’ä½“ä¼˜åŒ–çš„ä¼šè¯"""
        session = requests.Session()
        
        # ä½¿ç”¨VLCæ’­æ”¾å™¨çš„User-Agentï¼Œä½†ä¿æŒç®€å•çš„headers
        session.headers.update({
            'User-Agent': 'VLC/3.0.16 LibVLC/3.0.16'
        })
        
        return session

    def test_stream_speed(self, channel: ChannelInfo, timeout=8):
        """æµ‹è¯•å•ä¸ªæµåª’ä½“é€Ÿåº¦ - ä½¿ç”¨VLC User-Agent"""
        # å¢åŠ é‡è¯•æœºåˆ¶ï¼ŒæŸäº›IPTVæºå¯èƒ½éœ€è¦å¤šæ¬¡å°è¯•
        max_retries = 2
        
        for attempt in range(max_retries):
            try:
                # åˆ›å»ºæµåª’ä½“ä¼˜åŒ–çš„ä¼šè¯
                session = self._create_streaming_session()
                
                # å¤„ç†å¸¦æŸ¥è¯¢å‚æ•°çš„URLï¼Œå¦‚ .m3u8?xxx
                # ä¿®å¤: åŸæ¥ä½¿ç”¨ endswith('.m3u8') æ— æ³•æ­£ç¡®è¯†åˆ«å¸¦æŸ¥è¯¢å‚æ•°çš„M3U8 URL
                url_path = channel.url.split('?')[0]  # å»æ‰æŸ¥è¯¢å‚æ•°éƒ¨åˆ†
                if url_path.endswith('.m3u8'):
                    result = self._test_m3u8_speed(session, channel, timeout)
                else:
                    result = self._test_direct_stream_speed(session, channel, timeout)
                
                # å¦‚æœæµ‹è¯•æˆåŠŸï¼ˆé€Ÿåº¦ > 0ï¼‰ï¼Œç›´æ¥è¿”å›ç»“æœ
                if result.speed > 0:
                    return result
                    
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè¿”å›å¤±è´¥ç»“æœ
                if attempt == max_retries - 1:
                    return result
                    
            except Exception as e:
                # è®°å½•é”™è¯¯ä½†ç»§ç»­å°è¯•
                if attempt == max_retries - 1:
                    # æœ€åä¸€æ¬¡å°è¯•ä¹Ÿå¤±è´¥äº†
                    pass
        
        channel.speed = 0.0
        return channel
    
    def _test_problematic_iptv_server(self, session, channel: ChannelInfo):
        """ä¸“é—¨å¤„ç†æœ‰é—®é¢˜çš„IPTVæœåŠ¡å™¨ï¼Œä½¿ç”¨å®Œæ•´æµè§ˆå™¨æ¨¡æ‹Ÿ"""
        
        # è¯†åˆ«ZTE OTTæœåŠ¡å™¨ï¼ˆè·¯å¾„åŒ…å«030000001000ä¸”URLä»¥m3u8?ç»“å°¾çš„å…¸å‹ç‰¹å¾ï¼‰
        is_zte_ott = ('000000' in channel.url and channel.url.endswith('m3u8?'))
        
        if is_zte_ott:
            print(f"  æ£€æµ‹åˆ°ZTE OTTæœåŠ¡å™¨ï¼Œå°è¯•ç‰¹æ®Šå¤„ç†: {channel.name}")
            
            # æ–¹æ³•1: å®Œæ•´æµè§ˆå™¨æ¨¡æ‹Ÿ
            browser_result = self._browser_simulation_test(channel)
            if browser_result:
                return browser_result
            
            # æ–¹æ³•2: å°è¯•ä¸åŒçš„User-Agentï¼ˆå›é€€æ–¹æ¡ˆï¼‰
            user_agents = [
                'VLC/3.0.16 LibVLC/3.0.16',
                'ffmpeg/4.4.0', 
                'curl/8.5.0',
                'Mozilla/5.0 (compatible; IPTV-Player)',
            ]
            
            for ua in user_agents:
                try:
                    test_session = requests.Session()
                    test_session.headers.update({'User-Agent': ua})
                    
                    # å°è¯•è®¿é—®
                    response = test_session.get(channel.url, timeout=8, allow_redirects=True)
                    
                    if response.status_code == 200 and response.text.strip().startswith('#EXTM3U'):
                        print(f"  âœ“ ä½¿ç”¨ {ua} æˆåŠŸ")
                        return self._calculate_speed_from_m3u8(test_session, channel, response.text)
                    
                    # å¦‚æœæ˜¯302é‡å®šå‘ï¼Œæ‰‹åŠ¨å¤„ç†
                    if response.history:
                        print(f"  å‘ç°é‡å®šå‘å†å²: {[r.url for r in response.history]}")
                        if response.text.strip().startswith('#EXTM3U'):
                            return self._calculate_speed_from_m3u8(test_session, channel, response.text)
                    
                except Exception as e:
                    continue
            
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œæ ‡è®°ä¸ºé—®é¢˜æº
            print(f"  âœ— æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œå¯èƒ½æ˜¯æœåŠ¡å™¨ä¸´æ—¶ä¸å¯ç”¨")
            
        return None

    def _browser_simulation_test(self, channel: ChannelInfo):
        """å®Œæ•´çš„æµè§ˆå™¨æ¨¡æ‹Ÿæµ‹è¯•ï¼Œä¸“é—¨å¤„ç†ZTE OTTæœåŠ¡å™¨"""
        try:
            # æ–¹æ³•1: ä½¿ç”¨urllibï¼ˆZTE OTTæœåŠ¡å™¨æ‹’ç»requestsä½†æ¥å—urllibï¼‰
            import urllib.request
            import urllib.error
            
            print(f"    ğŸŒ ä½¿ç”¨urllibæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®...")
            
            # åˆ›å»ºè¯·æ±‚
            req = urllib.request.Request(channel.url)
            req.add_header('User-Agent', 'curl/8.5.0')
            req.add_header('Accept', '*/*')
            
            try:
                # å‘é€è¯·æ±‚
                response = urllib.request.urlopen(req, timeout=10)
                
                if response.status == 200:
                    print(f"    âœ… urllibè®¿é—®æˆåŠŸï¼ŒçŠ¶æ€ç : {response.status}")
                    
                    # è¯»å–M3U8å†…å®¹è¿›è¡ŒéªŒè¯
                    content = response.read(500).decode('utf-8', errors='ignore')
                    
                    if '#EXTM3U' in content:
                        print(f"    ğŸ¯ ç¡®è®¤M3U8æ ¼å¼ï¼Œå¼€å§‹é€Ÿåº¦æµ‹è¯•...")
                        
                        # é‡æ–°æ‰“å¼€è¿æ¥è¿›è¡Œé€Ÿåº¦æµ‹è¯•
                        req2 = urllib.request.Request(channel.url)
                        req2.add_header('User-Agent', 'curl/8.5.0')
                        req2.add_header('Accept', '*/*')
                        
                        response2 = urllib.request.urlopen(req2, timeout=10)
                        
                        # é€Ÿåº¦æµ‹è¯•
                        start_time = time.time()
                        total_size = 0
                        chunk_count = 0
                        
                        while chunk_count < 50:  # è¯»å–æ›´å¤šæ•°æ®ä»¥è·å¾—å‡†ç¡®é€Ÿåº¦
                            chunk = response2.read(8192)
                            if not chunk:
                                break
                            total_size += len(chunk)
                            chunk_count += 1
                            
                            # é¿å…æµ‹è¯•æ—¶é—´è¿‡é•¿
                            if time.time() - start_time > 8:
                                break
                        
                        end_time = time.time()
                        duration = end_time - start_time
                        response2.close()
                        
                        if total_size > 0 and duration > 0:
                            speed_mbps = (total_size / duration) / (1024 * 1024)
                            channel.speed = round(max(speed_mbps, 0.1), 2)
                            print(f"    ğŸš€ urllibæˆåŠŸï¼Œé€Ÿåº¦: {channel.speed} MB/s")
                            return channel
                    else:
                        print(f"    âŒ ä¸æ˜¯æœ‰æ•ˆçš„M3U8å†…å®¹")
                        
                response.close()
                        
            except urllib.error.HTTPError as e:
                if e.code == 302:
                    # å¤„ç†é‡å®šå‘
                    redirect_url = e.headers.get('Location')
                    if redirect_url:
                        print(f"    ğŸ“¡ æ£€æµ‹åˆ°302é‡å®šå‘ï¼Œå°è¯•è®¿é—®: {redirect_url[:60]}...")
                        
                        req_redirect = urllib.request.Request(redirect_url)
                        req_redirect.add_header('User-Agent', 'curl/8.5.0')
                        req_redirect.add_header('Accept', '*/*')
                        
                        response_redirect = urllib.request.urlopen(req_redirect, timeout=10)
                        
                        if response_redirect.status == 200:
                            content = response_redirect.read(300).decode('utf-8', errors='ignore')
                            if '#EXTM3U' in content:
                                print(f"    âœ… é‡å®šå‘åæˆåŠŸè·å–M3U8")
                                # ç®€åŒ–çš„é€Ÿåº¦æµ‹è¯•
                                channel.speed = 1.0  # ç»™ä¸€ä¸ªåˆç†çš„é»˜è®¤é€Ÿåº¦
                                response_redirect.close()
                                return channel
                        response_redirect.close()
                else:
                    print(f"    âŒ urllib HTTPé”™è¯¯: {e.code}")
            
            # æ–¹æ³•2: å›é€€åˆ°requestsçš„æµè§ˆå™¨æ¨¡æ‹Ÿï¼ˆç”¨äºå…¶ä»–ç±»å‹æœåŠ¡å™¨ï¼‰
            print(f"    ğŸ”„ urllibå¤±è´¥ï¼Œå°è¯•requestsæµè§ˆå™¨æ¨¡æ‹Ÿ...")
            return self._requests_browser_simulation(channel)
            
        except Exception as e:
            print(f"    âŒ æµè§ˆå™¨æ¨¡æ‹Ÿå¤±è´¥: {str(e)[:50]}")
            
        return None

    def _requests_browser_simulation(self, channel: ChannelInfo):
        """ä½¿ç”¨requestsçš„æµè§ˆå™¨æ¨¡æ‹Ÿï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        try:
            browser_session = requests.Session()
            
            browser_headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
            
            browser_session.headers.update(browser_headers)
            
            response = browser_session.get(channel.url, timeout=10, allow_redirects=False)
            
            if response.status_code == 302:
                redirect_url = response.headers.get('Location')
                if redirect_url and 'IASHttpSessionId' in redirect_url:
                    final_response = browser_session.get(redirect_url, timeout=10, stream=True)
                    
                    if final_response.status_code == 200:
                        content_sample = ''
                        total_size = 0
                        start_time = time.time()
                        
                        for chunk in final_response.iter_content(chunk_size=8192):
                            if chunk:
                                total_size += len(chunk)
                                if not content_sample:
                                    content_sample = chunk.decode('utf-8', errors='ignore')[:300]
                                    if '#EXTM3U' not in content_sample:
                                        browser_session.close()
                                        return None
                                
                                if total_size >= 100*1024:  # 100KB
                                    break
                        
                        end_time = time.time()
                        duration = end_time - start_time
                        
                        if total_size > 0 and duration > 0:
                            speed_mbps = (total_size / duration) / (1024 * 1024)
                            channel.speed = round(max(speed_mbps, 0.1), 2)
                            browser_session.close()
                            return channel
                            
            elif response.status_code == 200:
                content = response.text[:300]
                if '#EXTM3U' in content:
                    channel.speed = 1.0  # é»˜è®¤é€Ÿåº¦
                    browser_session.close()
                    return channel
            
            browser_session.close()
            
        except Exception:
            pass
            
        return None
    
    def _calculate_speed_from_m3u8(self, session, channel: ChannelInfo, m3u8_content):
        """ä»M3U8å†…å®¹è®¡ç®—é€Ÿåº¦"""
        try:
            # è§£æM3U8æ–‡ä»¶ï¼Œæå–TSåˆ†ç‰‡URL
            ts_urls = self._extract_ts_urls(m3u8_content, channel.url)
            
            if not ts_urls:
                channel.speed = 0.0
                return channel
            
            # æµ‹è¯•ç¬¬ä¸€ä¸ªTSåˆ†ç‰‡çš„é€Ÿåº¦
            ts_url = ts_urls[0]
            start_time = time.time()
            
            response = session.get(ts_url, stream=True, timeout=5)
            response.raise_for_status()
            
            downloaded_size = 0
            target_size = 1 * 1024 * 1024  # 1MB
            
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    downloaded_size += len(chunk)
                    
                current_time = time.time()
                if (current_time - start_time) > 4:
                    break
                    
                if downloaded_size >= target_size:
                    break
            
            elapsed_time = time.time() - start_time
            min_size = 128 * 1024  # æœ€å°‘128KBæ‰è®¡ç®—é€Ÿåº¦
            
            if elapsed_time > 0 and downloaded_size >= min_size:
                speed = downloaded_size / elapsed_time / 1024 / 1024  # MB/s
                channel.speed = round(speed, 2)
            else:
                channel.speed = 0.0
                
            return channel
            
        except Exception:
            channel.speed = 0.0
            return channel

    def _test_m3u8_speed(self, session, channel: ChannelInfo, timeout=8):
        """æµ‹è¯•M3U8æµåª’ä½“é€Ÿåº¦ - æ”¯æŒé—®é¢˜æœåŠ¡å™¨ç‰¹æ®Šå¤„ç†"""
        try:
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„é—®é¢˜æœåŠ¡å™¨
            special_result = self._test_problematic_iptv_server(session, channel)
            if special_result is not None:
                return special_result
            
            # æ ‡å‡†çš„M3U8æµ‹è¯•æµç¨‹
            m3u8_response = session.get(channel.url, timeout=5)
            m3u8_response.raise_for_status()
            m3u8_content = m3u8_response.text
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„M3U8å†…å®¹
            if not m3u8_content.strip().startswith('#EXTM3U'):
                channel.speed = 0.0
                return channel
            
            return self._calculate_speed_from_m3u8(session, channel, m3u8_content)
            
        except Exception:
            channel.speed = 0.0
            return channel
    
    def _extract_ts_urls(self, m3u8_content, base_url):
        """ä»M3U8å†…å®¹ä¸­æå–TSæ–‡ä»¶URL"""
        ts_urls = []
        lines = m3u8_content.split('\n')
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#'):
                # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œæ‹¼æ¥å®Œæ•´URL
                if not line.startswith('http'):
                    from urllib.parse import urljoin
                    ts_url = urljoin(base_url, line)
                else:
                    ts_url = line
                ts_urls.append(ts_url)
        
        return ts_urls
    
    def _test_direct_stream_speed(self, session, channel: ChannelInfo, timeout=8):
        """æµ‹è¯•ç›´æ¥æµåª’ä½“é€Ÿåº¦"""
        try:
            # ä¸‹è½½å‰2MBæ•°æ®è®¡ç®—é€Ÿåº¦ï¼Œç¼©çŸ­æµ‹è¯•æ—¶é—´
            response = session.get(channel.url, stream=True, timeout=timeout)
            response.raise_for_status()
            
            downloaded_size = 0
            target_size = 2 * 1024 * 1024  # 2MB
            min_size = 256 * 1024  # æœ€å°‘ä¸‹è½½256KBæ‰è®¡ç®—é€Ÿåº¦
            
            # è®°å½•å¼€å§‹ä¸‹è½½æ•°æ®çš„æ—¶é—´
            data_start_time = time.time()
            
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    downloaded_size += len(chunk)
                    current_time = time.time()
                    
                    # å¦‚æœä¸‹è½½æ—¶é—´è¶…è¿‡5ç§’å°±åœæ­¢
                    if (current_time - data_start_time) > 5:
                        break
                        
                    # è¾¾åˆ°ç›®æ ‡å¤§å°å°±åœæ­¢
                    if downloaded_size >= target_size:
                        break
            
            # è®¡ç®—é€Ÿåº¦
            elapsed_time = time.time() - data_start_time
            if elapsed_time > 0 and downloaded_size >= min_size:
                speed = downloaded_size / elapsed_time / 1024 / 1024  # MB/s
                channel.speed = round(speed, 2)
            else:
                channel.speed = 0.0
                
            return channel
            
        except Exception:
            channel.speed = 0.0
            return channel
    
    def speed_test_channels(self, channels):
        """å¹¶å‘æµ‹é€Ÿæ‰€æœ‰é¢‘é“"""
        print(f"å¼€å§‹æµ‹é€Ÿ {len(channels)} ä¸ªé¢‘é“...")
        
        # åˆå§‹åŒ–æµ‹é€Ÿæ—¥å¿—æ–‡ä»¶
        self._init_speed_log()
        
        def test_single_channel(index, channel):
            import signal
            import threading
            
            result_container = [None]
            exception_container = [None]
            
            def timeout_handler():
                # è¶…æ—¶å¤„ç†å‡½æ•°
                exception_container[0] = "timeout"
            
            def test_worker():
                try:
                    result_container[0] = self.test_stream_speed(channel, timeout=8)
                except Exception as e:
                    exception_container[0] = str(e)
            
            # åˆ›å»ºæµ‹è¯•çº¿ç¨‹
            test_thread = threading.Thread(target=test_worker)
            test_thread.daemon = True
            test_thread.start()
            
            # ç­‰å¾…æœ€å¤š12ç§’
            test_thread.join(timeout=12)
            
            if test_thread.is_alive():
                # çº¿ç¨‹è¿˜åœ¨è¿è¡Œï¼Œè¯´æ˜è¶…æ—¶äº†
                channel.speed = 0.0
                result = channel
                print(f"[{index+1}/{len(channels)}] {channel.name}: è¶…æ—¶")
            elif exception_container[0]:
                # å‘ç”Ÿå¼‚å¸¸
                channel.speed = 0.0
                result = channel
                print(f"[{index+1}/{len(channels)}] {channel.name}: æµ‹è¯•å¤±è´¥")
            elif result_container[0]:
                # æµ‹è¯•æˆåŠŸ
                result = result_container[0]
                if result.speed > 0:
                    print(f"[{index+1}/{len(channels)}] {channel.name}: {result.speed:.2f} MB/s")
                else:
                    print(f"[{index+1}/{len(channels)}] {channel.name}: æµ‹è¯•å¤±è´¥")
            else:
                # æœªçŸ¥æƒ…å†µ
                channel.speed = 0.0
                result = channel
                print(f"[{index+1}/{len(channels)}] {channel.name}: æœªçŸ¥é”™è¯¯")
            
            # å†™å…¥æµ‹é€Ÿæ—¥å¿—
            self._write_speed_log(channel.name, channel.url, result.speed)
            
            return result
        
        tested_channels = []
        
        # è¿›ä¸€æ­¥å‡å°‘å¹¶å‘æ•°ï¼Œé¿å…ç½‘ç»œæ‹¥å µå’Œç³»ç»Ÿèµ„æºè€—å°½
        with ThreadPoolExecutor(max_workers=8) as executor:
            futures = [executor.submit(test_single_channel, i, channel) 
                      for i, channel in enumerate(channels)]
            
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=15)  # ç»™futureæœ¬èº«ä¹ŸåŠ ä¸ªè¶…æ—¶
                    if result.speed > 0:
                        tested_channels.append(result)
                except Exception as e:
                    print(f"è·å–æµ‹è¯•ç»“æœæ—¶å‡ºé”™: {e}")
                    continue
        
        print(f"æµ‹é€Ÿå®Œæˆï¼Œæœ‰æ•ˆé¢‘é“: {len(tested_channels)}")
        print(f"æµ‹é€Ÿæ—¥å¿—å·²ä¿å­˜åˆ°: {self.speed_log}")
        return tested_channels
    
    def _init_speed_log(self):
        """åˆå§‹åŒ–æµ‹é€Ÿæ—¥å¿—æ–‡ä»¶"""
        try:
            with open(self.speed_log, 'w', encoding='utf-8') as f:
                f.write("# IPTVé¢‘é“æµ‹é€Ÿæ—¥å¿—\n")
                f.write(f"# å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("# æ ¼å¼: é¢‘é“åç§° | ä¸‹è½½é€Ÿåº¦(MB/s) | æµåª’ä½“åœ°å€\n\n")
        except Exception as e:
            print(f"âœ— åˆå§‹åŒ–æµ‹é€Ÿæ—¥å¿—å¤±è´¥: {e}")
    
    def _write_speed_log(self, channel_name, url, speed):
        """å†™å…¥æµ‹é€Ÿæ—¥å¿—"""
        try:
            with open(self.speed_log, 'a', encoding='utf-8') as f:
                if speed > 0:
                    f.write(f"{channel_name} | {speed:.2f} MB/s | {url}\n")
                else:
                    f.write(f"{channel_name} | æµ‹è¯•å¤±è´¥ | {url}\n")
        except Exception as e:
            print(f"âœ— å†™å…¥æµ‹é€Ÿæ—¥å¿—å¤±è´¥: {e}")
    
    def _select_top_urls_per_channel(self, tested_channels):
        """ä¸ºæ¯ä¸ªé¢‘é“é€‰æ‹©é€Ÿåº¦æœ€å¿«çš„å‰Nä¸ªURL"""
        print(f"ä¸ºæ¯ä¸ªé¢‘é“é€‰æ‹©é€Ÿåº¦æœ€å¿«çš„å‰ {self.top_count} ä¸ªURLæº...")
        
        # æŒ‰é¢‘é“ååˆ†ç»„
        channel_groups = {}
        for channel in tested_channels:
            if channel.speed > 0:  # åªè€ƒè™‘æµ‹é€ŸæˆåŠŸçš„é¢‘é“
                if channel.name not in channel_groups:
                    channel_groups[channel.name] = []
                channel_groups[channel.name].append(channel)
        
        # ä¸ºæ¯ä¸ªé¢‘é“é€‰æ‹©å‰Nä¸ªæœ€å¿«çš„URL
        selected_channels = []
        for channel_name, channels in channel_groups.items():
            # æŒ‰é€Ÿåº¦é™åºæ’åº
            channels.sort(key=lambda x: x.speed, reverse=True)
            
            # å–å‰Nä¸ª
            top_channels_for_this_name = channels[:self.top_count]
            selected_channels.extend(top_channels_for_this_name)
            
            # æ‰“å°æ¯ä¸ªé¢‘é“çš„ä¿ç•™æƒ…å†µ
            if len(channels) > self.top_count:
                print(f"  {channel_name}: ä» {len(channels)} ä¸ªæºä¸­ä¿ç•™å‰ {len(top_channels_for_this_name)} ä¸ª")
            else:
                print(f"  {channel_name}: ä¿ç•™å…¨éƒ¨ {len(top_channels_for_this_name)} ä¸ªæº")
        
        return selected_channels
    
    def group_channel(self, channel_name):
        """å¯¹é¢‘é“è¿›è¡Œåˆ†ç»„"""
        name = channel_name.lower()
        
        if "cctv" in name or "cgtn" in name:
            return ChannelGroup.CCTV
        
        if any(key in channel_name for key in self.hkmotw):
            return ChannelGroup.HKMOTW
        
        if any(key in channel_name for key in self.wei_shi):
            return ChannelGroup.WEI_SHI
            
        if any(key in channel_name for key in self.locals):
            return ChannelGroup.LOCAL
            
        if any(key in channel_name for key in self.citys):
            return ChannelGroup.CITY
            
        return ChannelGroup.OTHER
    
    def group_channels(self, channels):
        """å°†é¢‘é“æŒ‰ç»„åˆ†ç±»"""
        grouped = {
            ChannelGroup.CCTV: [],
            ChannelGroup.WEI_SHI: [],
            ChannelGroup.LOCAL: [],
            ChannelGroup.HKMOTW: [],
            ChannelGroup.CITY: [],
            ChannelGroup.OTHER: []
        }
        
        for channel in channels:
            group = self.group_channel(channel.name)
            grouped[group].append(channel)
        
        # åœ¨æ¯ä¸ªåˆ†ç»„å†…ï¼ŒæŒ‰é¢‘é“åç§°å’Œé€Ÿåº¦æ’åº
        for group_name in grouped:
            # å…ˆæŒ‰é¢‘é“åç§°åˆ†ç»„ï¼Œå†åœ¨æ¯ä¸ªé¢‘é“å†…æŒ‰é€Ÿåº¦æ’åº
            channel_dict = {}
            for channel in grouped[group_name]:
                if channel.name not in channel_dict:
                    channel_dict[channel.name] = []
                channel_dict[channel.name].append(channel)
            
            # å¯¹æ¯ä¸ªé¢‘é“å†…çš„URLæŒ‰é€Ÿåº¦æ’åºï¼ˆå¿«åˆ°æ…¢ï¼‰
            sorted_channels = []
            
            # CCTVé¢‘é“ç‰¹æ®Šæ’åºï¼šæŒ‰æ•°å­—å¤§å°æ’åº
            if group_name == ChannelGroup.CCTV:
                def cctv_sort_key(channel_name):
                    # æå–CCTVåé¢çš„æ•°å­—
                    match = re.search(r'CCTV(\d+)', channel_name, re.IGNORECASE)
                    if match:
                        return int(match.group(1))
                    # éæ•°å­—CCTVé¢‘é“ï¼ˆå¦‚CGTNï¼‰æ’åœ¨æœ€å
                    return 999
                
                # æŒ‰CCTVæ•°å­—å¤§å°æ’åº
                sorted_channel_names = sorted(channel_dict.keys(), key=cctv_sort_key)
            else:
                # å…¶ä»–åˆ†ç»„æŒ‰é¢‘é“åç§°å­—æ¯æ’åº
                sorted_channel_names = sorted(channel_dict.keys())
            
            for channel_name in sorted_channel_names:
                channel_urls = channel_dict[channel_name]
                channel_urls.sort(key=lambda x: x.speed, reverse=True)
                sorted_channels.extend(channel_urls)
            
            grouped[group_name] = sorted_channels
        
        return grouped
    
    def generate_m3u_file(self, grouped_channels, output_path):
        """ç”ŸæˆM3Uæ ¼å¼çš„æ’­æ”¾åˆ—è¡¨æ–‡ä»¶"""
        print(f"ç”ŸæˆM3Uæ–‡ä»¶: {output_path}")
        
        # æŒ‰ç»„çš„ä¼˜å…ˆçº§æ’åº
        group_order = [
            ChannelGroup.CCTV,
            ChannelGroup.WEI_SHI, 
            ChannelGroup.HKMOTW,
            ChannelGroup.LOCAL,
            ChannelGroup.CITY,
            ChannelGroup.OTHER
        ]
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("#EXTM3U\n")
            
            for group_name in group_order:
                channels = grouped_channels.get(group_name, [])
                if not channels:
                    continue
                
                # æŒ‰é¢‘é“åç§°åˆå¹¶ï¼Œæ˜¾ç¤ºé€Ÿåº¦ä¿¡æ¯
                channel_dict = {}
                for channel in channels:
                    if channel.name not in channel_dict:
                        channel_dict[channel.name] = []
                    channel_dict[channel.name].append(channel)
                
                # CCTVé¢‘é“ç‰¹æ®Šæ’åºé€»è¾‘
                if group_name == ChannelGroup.CCTV:
                    def cctv_sort_key(channel_name):
                        # æå–CCTVåé¢çš„æ•°å­—
                        match = re.search(r'CCTV(\d+)', channel_name, re.IGNORECASE)
                        if match:
                            return int(match.group(1))
                        # éæ•°å­—CCTVé¢‘é“ï¼ˆå¦‚CGTNï¼‰æ’åœ¨æœ€å
                        return 999
                    sorted_channel_names = sorted(channel_dict.keys(), key=cctv_sort_key)
                else:
                    sorted_channel_names = sorted(channel_dict.keys())
                
                # å†™å…¥æ¯ä¸ªé¢‘é“çš„æ¯ä¸ªURLï¼ˆåœ¨M3Uä¸­åˆ†åˆ«åˆ—å‡ºï¼‰
                for channel_name in sorted_channel_names:
                    channel_urls = channel_dict[channel_name]
                    # ç¡®ä¿æŒ‰é€Ÿåº¦æ’åºï¼ˆå¿«åˆ°æ…¢ï¼‰
                    channel_urls.sort(key=lambda x: x.speed, reverse=True)
                    
                    for channel in channel_urls:
                        # ç»Ÿä¸€ä½¿ç”¨é¢‘é“åï¼Œä¸æ·»åŠ åºå·å’Œé€Ÿåº¦ä¿¡æ¯
                        f.write(f'#EXTINF:-1 group-title="{group_name}",{channel.name}\n')
                        f.write(f'{channel.url}\n')
        
        print(f"M3Uæ–‡ä»¶å·²ç”Ÿæˆï¼ŒåŒ…å«ä»¥ä¸‹åˆ†ç»„:")
        for group_name in group_order:
            count = len(grouped_channels.get(group_name, []))
            if count > 0:
                print(f"  {group_name}: {count} ä¸ªé¢‘é“æº")
    
    def generate_txt_file(self, grouped_channels, output_path):
        """ç”ŸæˆTXTæ ¼å¼çš„æ’­æ”¾åˆ—è¡¨æ–‡ä»¶"""
        print(f"ç”ŸæˆTXTæ–‡ä»¶: {output_path}")
        
        # æŒ‰ç»„çš„ä¼˜å…ˆçº§æ’åº
        group_order = [
            ChannelGroup.CCTV,
            ChannelGroup.WEI_SHI,
            ChannelGroup.HKMOTW,
            ChannelGroup.LOCAL, 
            ChannelGroup.CITY,
            ChannelGroup.OTHER
        ]
        
        with open(output_path, 'w', encoding='utf-8') as f:
            for group_name in group_order:
                channels = grouped_channels.get(group_name, [])
                if not channels:
                    continue
                    
                f.write(f"{group_name},#genre#\n")
                
                # æŒ‰é¢‘é“åç§°åˆå¹¶å¤šä¸ªURL
                channel_dict = {}
                for channel in channels:
                    if channel.name not in channel_dict:
                        channel_dict[channel.name] = []
                    channel_dict[channel.name].append(channel)
                
                # CCTVé¢‘é“ç‰¹æ®Šæ’åºé€»è¾‘
                if group_name == ChannelGroup.CCTV:
                    def cctv_sort_key(channel_name):
                        # æå–CCTVåé¢çš„æ•°å­—
                        match = re.search(r'CCTV(\d+)', channel_name, re.IGNORECASE)
                        if match:
                            return int(match.group(1))
                        # éæ•°å­—CCTVé¢‘é“ï¼ˆå¦‚CGTNï¼‰æ’åœ¨æœ€å
                        return 999
                    sorted_channel_names = sorted(channel_dict.keys(), key=cctv_sort_key)
                else:
                    sorted_channel_names = sorted(channel_dict.keys())
                
                # å†™å…¥æ¯ä¸ªé¢‘é“ï¼ˆæ¯ä¸ªURLå•ç‹¬ä¸€è¡Œï¼‰
                for channel_name in sorted_channel_names:
                    channel_urls = channel_dict[channel_name]
                    # ç¡®ä¿æŒ‰é€Ÿåº¦æ’åºï¼ˆå¿«åˆ°æ…¢ï¼‰
                    channel_urls.sort(key=lambda x: x.speed, reverse=True)
                    
                    for channel in channel_urls:
                        f.write(f"{channel.name},{channel.url}\n")
                
                f.write("\n")
    
    def run(self):
        """è¿è¡Œä¸»æµç¨‹"""
        print("=== IPTVç›´æ’­æºå¤„ç†å·¥å…· ===")
        
        # 1. ä¸‹è½½æ–‡ä»¶
        downloaded_files = self.download_files()
        if not downloaded_files:
            print("æ²¡æœ‰æˆåŠŸä¸‹è½½ä»»ä½•æ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
            return
            
        # 2. è§£æé¢‘é“
        all_channels = self.parse_txt_files(downloaded_files)
        if not all_channels:
            print("æ²¡æœ‰è§£æåˆ°ä»»ä½•é¢‘é“ï¼Œç¨‹åºé€€å‡º")
            return
        
        # 3. å»é‡ï¼ˆåŸºäºé¢‘é“åå’ŒURLï¼‰
        unique_channels = []
        seen = set()
        for channel in all_channels:
            key = f"{channel.name}_{channel.url}"
            if key not in seen:
                seen.add(key)
                unique_channels.append(channel)
        
        print(f"å»é‡åå‰©ä½™ {len(unique_channels)} ä¸ªé¢‘é“")
        
        # 4. æµ‹é€Ÿ
        tested_channels = self.speed_test_channels(unique_channels)
        
        # 5. æŒ‰é¢‘é“ååˆ†ç»„ï¼Œæ¯ä¸ªé¢‘é“ä¿ç•™é€Ÿåº¦æœ€å¿«çš„å‰Nä¸ªURL
        top_channels = self._select_top_urls_per_channel(tested_channels)
        
        print(f"å¤„ç†åæ€»å…±ä¿ç•™ {len(top_channels)} ä¸ªé¢‘é“æº")
        
        # 6. é‡æ–°åˆ†ç»„
        grouped_channels = self.group_channels(top_channels)
        
        # 7. ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        m3u_output = self.output_dir / "unicast_result.m3u"
        txt_output = self.output_dir / "unicast_result.txt"
        
        self.generate_m3u_file(grouped_channels, m3u_output)
        self.generate_txt_file(grouped_channels, txt_output)
        
        print("\n=== å¤„ç†å®Œæˆ ===")
        print(f"è¾“å‡ºæ–‡ä»¶:")
        print(f"  M3Uæ ¼å¼: {m3u_output}")
        print(f"  TXTæ ¼å¼: {txt_output}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='IPTVç›´æ’­æºä¸‹è½½ã€åˆå¹¶ã€æµ‹é€Ÿä¸åˆ†ç»„å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('--top', type=int, default=20,
                       help='æ¯ä¸ªé¢‘é“æœ€å¤šä¿ç•™é€Ÿåº¦æœ€å¿«çš„å‰Nä¸ªURLæº (é»˜è®¤: 20)')
    
    parser.add_argument('--proxy', type=str, default=None,
                       help='ä»£ç†æœåŠ¡å™¨åœ°å€ï¼Œæ ¼å¼ï¼šhttp://127.0.0.1:10808 (ä»…ç”¨äºä¸‹è½½URLåˆ—è¡¨)')
    
    args = parser.parse_args()
    
    if args.top < 1:
        print("é”™è¯¯: --top å‚æ•°å¿…é¡»å¤§äº0")
        sys.exit(1)
    
    processor = UnicastProcessor(top_count=args.top, proxy=args.proxy)
    processor.run()


if __name__ == "__main__":
    main()







